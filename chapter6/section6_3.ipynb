{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "section6_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P_ybgqLyDJwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #colabを使う方はこちらを使用ください。\n",
        "# !pip install torch==0.4.1\n",
        "# !pip install torchvision==0.2.1\n",
        "# !pip install numpy==1.14.6\n",
        "# !pip install matplotlib==2.1.2\n",
        "# !pip install pillow==5.0.0\n",
        "# !pip install opencv-python==3.4.3.18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JSI-ob1LXJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): \n",
        "    Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "    for extension in extensions: \n",
        "        register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGlfMTUfa-It",
        "colab_type": "code",
        "outputId": "face04d4-af74-44f8-ead0-edf0edf2ae75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "#Google Driveにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GpXhG3lzbSBK",
        "colab_type": "code",
        "outputId": "4a2073f5-ac8b-46ee-ee00-beaf86c321d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。※変更の必要がある場合はパスを変更してください。\n",
        "cd /content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dLtNvfx7bSSj",
        "colab_type": "code",
        "outputId": "34b4184b-9237-4df0-c73c-ec27e23bee5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "!ls "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net.py\t     result_cgan   section6_3.ipynb  train_cgan.py\n",
            "__pycache__  result_lsgan  section6_4.ipynb  train_lsgan.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rfdH0jXxC-pk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# パッケージのインポート\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from net import weights_init, Generator, Discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAp9p1iOC-pp",
        "colab_type": "code",
        "outputId": "c6c84d5b-4d45-4466-99e4-c64d0539115f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 設定\n",
        "workers = 2\n",
        "batch_size=50\n",
        "nz = 100\n",
        "nch_g = 64\n",
        "nch_d = 64\n",
        "n_epoch = 200\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "outf = './result_lsgan'\n",
        "display_interval = 100\n",
        "\n",
        "# 保存先ディレクトリを作成\n",
        "try:\n",
        "    os.makedirs(outf, exist_ok=True)\n",
        "except OSError as error: \n",
        "    print(error)\n",
        "    pass\n",
        "\n",
        "# 乱数のシード（種）を固定\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f07ec6b9c30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "uZLNaplkC-pt",
        "colab_type": "code",
        "outputId": "dd0191ec-3987-432a-9e43-cdc519742763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# STL-10のトレーニングデータセットとテストデータセットを読み込む\n",
        "trainset = dset.STL10(root='../../dataset/stl10_root', download=True, split='train+unlabeled',\n",
        "                      transform=transforms.Compose([\n",
        "                          transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                      ]))   # ラベルを使用しないのでラベルなしを混在した'train+unlabeled'を読み込む\n",
        "testset = dset.STL10(root='../../dataset/stl10_root', download=True, split='test',\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                         transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                     ]))\n",
        "dataset = trainset + testset    # STL-10のトレーニングデータセットとテストデータセットを合わせて訓練データとする\n",
        "\n",
        "# 訓練データをセットしたデータローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "# 学習に使用するデバイスを得る。可能ならGPUを使用する\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ../../dataset/stl10_root/stl10_binary.tar.gz\n",
            "Files already downloaded and verified\n",
            "device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vIJpbNtvC-pw",
        "colab_type": "code",
        "outputId": "c6337409-9447-4cda-9fb7-7fa7a6d1997e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "# 生成器G。ランダムベクトルから贋作画像を生成する\n",
        "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
        "netG.apply(weights_init)    # weights_init関数で初期化\n",
        "print(netG)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rriIYwAFC-pz",
        "colab_type": "code",
        "outputId": "21951289-3831-490f-ad2f-55a266cca25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# 識別器D。画像が、元画像か贋作画像かを識別する\n",
        "netD = Discriminator(nch_d=nch_d).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vjfl5HxRC-p1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
        "\n",
        "# オプティマイザ−のセットアップ\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  # 確認用の固定したノイズ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lckGpHvMC-p5",
        "colab_type": "code",
        "outputId": "44709856-a6de-4a38-99cb-407bed9b45f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2548
        }
      },
      "cell_type": "code",
      "source": [
        "# 学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "    for itr, data in enumerate(dataloader):\n",
        "        real_image = data[0].to(device)     # 元画像\n",
        "        sample_size = real_image.size(0)    # 画像枚数\n",
        "        noise = torch.randn(sample_size, nz, 1, 1, device=device)   # 正規分布からノイズを生成\n",
        "        \n",
        "        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n",
        "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n",
        "        \n",
        "        ############################\n",
        "        # 識別器Dの更新\n",
        "        ###########################\n",
        "        netD.zero_grad()    # 勾配の初期化\n",
        "\n",
        "        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n",
        "        \n",
        "        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
        "        errD.backward()    # 誤差逆伝播\n",
        "        optimizerD.step()   # Dのパラメーターを更新\n",
        "\n",
        "        ############################\n",
        "        # 生成器Gの更新\n",
        "        ###########################\n",
        "        netG.zero_grad()    # 勾配の初期化\n",
        "        \n",
        "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n",
        "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n",
        "        errG.backward()     # 誤差逆伝播\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        optimizerG.step()   # Gのパラメータを更新\n",
        "\n",
        "        if itr % display_interval == 0: \n",
        "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
        "                  .format(epoch + 1, n_epoch,\n",
        "                          itr + 1, len(dataloader),\n",
        "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n",
        "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
        "                              normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # 確認用画像の生成\n",
        "    ############################\n",
        "    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n",
        "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
        "                      normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # モデルの保存\n",
        "    ############################\n",
        "    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n",
        "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
        "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200][1/2260] Loss_D: 3.741 Loss_G: 18.048 D(x): 0.302 D(G(z)): -0.523/5.164\n",
            "[1/200][101/2260] Loss_D: 0.989 Loss_G: 1.852 D(x): 0.654 D(G(z)): -0.466/-0.278\n",
            "[1/200][201/2260] Loss_D: 9.078 Loss_G: 17.086 D(x): 1.329 D(G(z)): 2.922/-3.111\n",
            "[1/200][301/2260] Loss_D: 0.259 Loss_G: 1.244 D(x): 0.929 D(G(z)): 0.268/-0.101\n",
            "[1/200][401/2260] Loss_D: 0.202 Loss_G: 1.437 D(x): 1.099 D(G(z)): 0.206/-0.188\n",
            "[1/200][501/2260] Loss_D: 0.223 Loss_G: 1.222 D(x): 1.007 D(G(z)): 0.358/-0.081\n",
            "[1/200][601/2260] Loss_D: 0.251 Loss_G: 0.886 D(x): 1.016 D(G(z)): 0.342/0.080\n",
            "[1/200][701/2260] Loss_D: 0.267 Loss_G: 1.072 D(x): 0.837 D(G(z)): 0.334/-0.004\n",
            "[1/200][801/2260] Loss_D: 0.444 Loss_G: 0.383 D(x): 0.561 D(G(z)): -0.262/0.422\n",
            "[1/200][901/2260] Loss_D: 0.121 Loss_G: 0.897 D(x): 0.872 D(G(z)): 0.077/0.065\n",
            "[1/200][1001/2260] Loss_D: 0.147 Loss_G: 0.704 D(x): 0.723 D(G(z)): -0.044/0.173\n",
            "[1/200][1101/2260] Loss_D: 0.183 Loss_G: 0.804 D(x): 0.822 D(G(z)): -0.143/0.119\n",
            "[1/200][1201/2260] Loss_D: 0.174 Loss_G: 1.655 D(x): 1.073 D(G(z)): 0.281/-0.275\n",
            "[1/200][1301/2260] Loss_D: 0.108 Loss_G: 0.958 D(x): 0.872 D(G(z)): 0.100/0.032\n",
            "[1/200][1401/2260] Loss_D: 0.143 Loss_G: 0.700 D(x): 0.733 D(G(z)): 0.025/0.186\n",
            "[1/200][1501/2260] Loss_D: 0.158 Loss_G: 0.849 D(x): 0.921 D(G(z)): 0.141/0.097\n",
            "[1/200][1601/2260] Loss_D: 0.450 Loss_G: 0.938 D(x): 1.010 D(G(z)): 0.515/0.058\n",
            "[1/200][1701/2260] Loss_D: 0.132 Loss_G: 0.963 D(x): 0.990 D(G(z)): 0.212/0.028\n",
            "[1/200][1801/2260] Loss_D: 0.252 Loss_G: 1.286 D(x): 0.989 D(G(z)): 0.402/-0.112\n",
            "[1/200][1901/2260] Loss_D: 0.105 Loss_G: 0.957 D(x): 0.832 D(G(z)): 0.080/0.032\n",
            "[1/200][2001/2260] Loss_D: 0.141 Loss_G: 1.011 D(x): 0.859 D(G(z)): 0.243/0.009\n",
            "[1/200][2101/2260] Loss_D: 0.219 Loss_G: 0.790 D(x): 0.748 D(G(z)): 0.212/0.132\n",
            "[1/200][2201/2260] Loss_D: 1.431 Loss_G: 0.107 D(x): 0.110 D(G(z)): -0.662/0.815\n",
            "[2/200][1/2260] Loss_D: 0.869 Loss_G: 1.646 D(x): 1.229 D(G(z)): 0.831/-0.261\n",
            "[2/200][101/2260] Loss_D: 0.558 Loss_G: 1.494 D(x): 1.108 D(G(z)): 0.590/-0.200\n",
            "[2/200][201/2260] Loss_D: 0.208 Loss_G: 0.684 D(x): 0.652 D(G(z)): -0.014/0.188\n",
            "[2/200][301/2260] Loss_D: 0.255 Loss_G: 0.862 D(x): 0.676 D(G(z)): 0.248/0.087\n",
            "[2/200][401/2260] Loss_D: 0.288 Loss_G: 1.037 D(x): 0.784 D(G(z)): 0.389/0.006\n",
            "[2/200][501/2260] Loss_D: 0.308 Loss_G: 0.854 D(x): 0.689 D(G(z)): 0.191/0.111\n",
            "[2/200][601/2260] Loss_D: 0.227 Loss_G: 1.138 D(x): 0.863 D(G(z)): 0.187/-0.040\n",
            "[2/200][701/2260] Loss_D: 0.224 Loss_G: 0.601 D(x): 0.679 D(G(z)): 0.131/0.245\n",
            "[2/200][801/2260] Loss_D: 0.593 Loss_G: 1.599 D(x): 1.173 D(G(z)): 0.591/-0.228\n",
            "[2/200][901/2260] Loss_D: 0.218 Loss_G: 0.758 D(x): 0.657 D(G(z)): -0.029/0.145\n",
            "[2/200][1001/2260] Loss_D: 0.229 Loss_G: 1.623 D(x): 0.981 D(G(z)): 0.154/-0.245\n",
            "[2/200][1101/2260] Loss_D: 0.274 Loss_G: 0.202 D(x): 0.562 D(G(z)): -0.091/0.588\n",
            "[2/200][1201/2260] Loss_D: 0.112 Loss_G: 0.943 D(x): 0.828 D(G(z)): 0.082/0.042\n",
            "[2/200][1301/2260] Loss_D: 0.329 Loss_G: 0.851 D(x): 0.658 D(G(z)): 0.333/0.097\n",
            "[2/200][1401/2260] Loss_D: 0.159 Loss_G: 1.533 D(x): 1.043 D(G(z)): 0.281/-0.226\n",
            "[2/200][1501/2260] Loss_D: 0.380 Loss_G: 0.813 D(x): 0.540 D(G(z)): 0.162/0.137\n",
            "[2/200][1601/2260] Loss_D: 0.341 Loss_G: 1.937 D(x): 1.156 D(G(z)): 0.480/-0.381\n",
            "[2/200][1701/2260] Loss_D: 0.361 Loss_G: 1.699 D(x): 0.816 D(G(z)): 0.440/-0.277\n",
            "[2/200][1801/2260] Loss_D: 0.454 Loss_G: 0.641 D(x): 0.487 D(G(z)): -0.030/0.241\n",
            "[2/200][1901/2260] Loss_D: 0.515 Loss_G: 2.007 D(x): 1.099 D(G(z)): 0.463/-0.374\n",
            "[2/200][2001/2260] Loss_D: 0.097 Loss_G: 0.874 D(x): 0.858 D(G(z)): 0.099/0.074\n",
            "[2/200][2101/2260] Loss_D: 0.104 Loss_G: 0.926 D(x): 0.839 D(G(z)): 0.088/0.057\n",
            "[2/200][2201/2260] Loss_D: 0.220 Loss_G: 0.799 D(x): 0.637 D(G(z)): -0.029/0.123\n",
            "[3/200][1/2260] Loss_D: 0.195 Loss_G: 1.229 D(x): 0.960 D(G(z)): 0.242/-0.093\n",
            "[3/200][101/2260] Loss_D: 0.242 Loss_G: 0.784 D(x): 0.638 D(G(z)): 0.147/0.127\n",
            "[3/200][201/2260] Loss_D: 0.200 Loss_G: 0.872 D(x): 0.724 D(G(z)): 0.169/0.082\n",
            "[3/200][301/2260] Loss_D: 0.258 Loss_G: 1.250 D(x): 1.005 D(G(z)): 0.354/-0.088\n",
            "[3/200][401/2260] Loss_D: 0.382 Loss_G: 0.259 D(x): 0.447 D(G(z)): 0.050/0.505\n",
            "[3/200][501/2260] Loss_D: 0.335 Loss_G: 1.562 D(x): 1.062 D(G(z)): 0.402/-0.206\n",
            "[3/200][601/2260] Loss_D: 0.142 Loss_G: 0.723 D(x): 0.798 D(G(z)): 0.131/0.165\n",
            "[3/200][701/2260] Loss_D: 0.223 Loss_G: 0.703 D(x): 0.716 D(G(z)): 0.115/0.179\n",
            "[3/200][801/2260] Loss_D: 0.401 Loss_G: 0.236 D(x): 0.449 D(G(z)): -0.071/0.543\n",
            "[3/200][901/2260] Loss_D: 0.241 Loss_G: 0.602 D(x): 0.634 D(G(z)): -0.095/0.240\n",
            "[3/200][1001/2260] Loss_D: 0.213 Loss_G: 1.070 D(x): 0.978 D(G(z)): 0.302/-0.019\n",
            "[3/200][1101/2260] Loss_D: 0.261 Loss_G: 0.706 D(x): 0.573 D(G(z)): 0.018/0.178\n",
            "[3/200][1201/2260] Loss_D: 0.267 Loss_G: 0.541 D(x): 0.617 D(G(z)): 0.023/0.391\n",
            "[3/200][1301/2260] Loss_D: 0.278 Loss_G: 0.918 D(x): 0.790 D(G(z)): 0.353/0.075\n",
            "[3/200][1401/2260] Loss_D: 0.337 Loss_G: 0.690 D(x): 0.608 D(G(z)): -0.191/0.244\n",
            "[3/200][1501/2260] Loss_D: 0.293 Loss_G: 1.260 D(x): 0.844 D(G(z)): 0.396/-0.106\n",
            "[3/200][1601/2260] Loss_D: 0.389 Loss_G: 0.708 D(x): 0.466 D(G(z)): 0.015/0.180\n",
            "[3/200][1701/2260] Loss_D: 0.412 Loss_G: 0.492 D(x): 0.468 D(G(z)): -0.064/0.321\n",
            "[3/200][1801/2260] Loss_D: 0.359 Loss_G: 0.894 D(x): 0.568 D(G(z)): 0.231/0.083\n",
            "[3/200][1901/2260] Loss_D: 0.848 Loss_G: 0.162 D(x): 0.202 D(G(z)): -0.303/0.649\n",
            "[3/200][2001/2260] Loss_D: 0.398 Loss_G: 1.160 D(x): 0.834 D(G(z)): 0.510/-0.054\n",
            "[3/200][2101/2260] Loss_D: 0.334 Loss_G: 0.787 D(x): 0.699 D(G(z)): 0.300/0.135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-6:\n",
            "Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
            "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
            "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\", line 81, in __getitem__\n",
            "    return self.datasets[dataset_idx][sample_idx]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/datasets/stl10.py\", line 108, in __getitem__\n",
            "    img = self.transform(img)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\", line 76, in __call__\n",
            "    return F.to_tensor(pic)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\", line 81, in to_tensor\n",
            "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
            "  File \"/usr/lib/python3.6/selectors.py\", line 376, in select\n",
            "    fd_event_list = self._poll.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-49d9f0317f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 識別器Dで元画像に対する識別信号を出力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0merrD_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_target\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 贋作画像に対する識別信号の損失値\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mD_G_z1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HnVHkaZAR7bp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}