{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "section6_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P_ybgqLyDJwh",
        "colab_type": "code",
        "outputId": "79fc4f31-1827-4270-cc90-1a2a73546103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "!pip install torch==0.4.1\n",
        "!pip install torchvision==0.2.1\n",
        "!pip install numpy==1.14.6\n",
        "!pip install matplotlib==2.1.2\n",
        "!pip install pillow==5.0.0\n",
        "!pip install opencv-python==3.4.3.18"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.4.1 in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (5.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (0.4.1)\n",
            "Requirement already satisfied: numpy==1.14.6 in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: matplotlib==2.1.2 in /usr/local/lib/python3.6/dist-packages (2.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (2.3.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (1.11.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (2018.7)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.1.2) (2.5.3)\n",
            "Requirement already satisfied: pillow==5.0.0 in /usr/local/lib/python3.6/dist-packages (5.0.0)\n",
            "Requirement already satisfied: opencv-python==3.4.3.18 in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.3.18) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VGlfMTUfa-It",
        "colab_type": "code",
        "outputId": "22d10889-f6c6-4c4b-91ad-163a374c7a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "#Google Driveにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GpXhG3lzbSBK",
        "colab_type": "code",
        "outputId": "7fb8cb1f-8736-49f7-befc-87364eb88502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。※変更の必要がある場合はパスを変更してください。\n",
        "cd /content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dLtNvfx7bSSj",
        "colab_type": "code",
        "outputId": "07bf6c96-125f-4005-84db-79cb4bd50cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net.py\t     result_lsgan      section6_4.ipynb  train_lsgan.py\n",
            "result_cgan  section6_3.ipynb  train_cgan.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rfdH0jXxC-pk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# パッケージのインポート\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from net import weights_init, Generator, Discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAp9p1iOC-pp",
        "colab_type": "code",
        "outputId": "264d9b29-a656-4e27-8007-cd5e6a427f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 設定\n",
        "workers = 2\n",
        "batch_size=50\n",
        "nz = 100\n",
        "nch_g = 64\n",
        "nch_d = 64\n",
        "n_epoch = 200\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "outf = './result_lsgan'\n",
        "display_interval = 100\n",
        "\n",
        "# 保存先ディレクトリを作成\n",
        "try:\n",
        "    os.makedirs(outf)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "# 乱数のシード（種）を固定\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb009424410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "uZLNaplkC-pt",
        "colab_type": "code",
        "outputId": "6392148e-cfe1-4b13-c7ff-3e85201ebd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# STL-10のトレーニングデータセットとテストデータセットを読み込む\n",
        "trainset = dset.STL10(root='../../dataset/stl10_root', download=True, split='train+unlabeled',\n",
        "                      transform=transforms.Compose([\n",
        "                          transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                      ]))   # ラベルを使用しないのでラベルなしを混在した'train+unlabeled'を読み込む\n",
        "testset = dset.STL10(root='../../dataset/stl10_root', download=True, split='test',\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                         transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                     ]))\n",
        "dataset = trainset + testset    # STL-10のトレーニングデータセットとテストデータセットを合わせて訓練データとする\n",
        "\n",
        "# 訓練データをセットしたデータローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "# 学習に使用するデバイスを得る。可能ならGPUを使用する\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vIJpbNtvC-pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "f5415657-7de8-4d2b-8078-c23435e62005"
      },
      "cell_type": "code",
      "source": [
        "# 生成器G。ランダムベクトルから贋作画像を生成する\n",
        "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
        "netG.apply(weights_init)    # weights_init関数で初期化\n",
        "print(netG)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rriIYwAFC-pz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "8f998719-d77b-4941-8f14-4b32d3c2a258"
      },
      "cell_type": "code",
      "source": [
        "# 識別器D。画像が、元画像か贋作画像かを識別する\n",
        "netD = Discriminator(nch_d=nch_d).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vjfl5HxRC-p1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
        "\n",
        "# オプティマイザ−のセットアップ\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  # 確認用の固定したノイズ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lckGpHvMC-p5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2315
        },
        "outputId": "82dbacb7-56a8-4810-b353-e8438b1d38ad"
      },
      "cell_type": "code",
      "source": [
        "# 学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "    for itr, data in enumerate(dataloader):\n",
        "        real_image = data[0].to(device)     # 元画像\n",
        "        sample_size = real_image.size(0)    # 画像枚数\n",
        "        noise = torch.randn(sample_size, nz, 1, 1, device=device)   # 正規分布からノイズを生成\n",
        "        \n",
        "        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n",
        "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n",
        "        \n",
        "        ############################\n",
        "        # 識別器Dの更新\n",
        "        ###########################\n",
        "        netD.zero_grad()    # 勾配の初期化\n",
        "\n",
        "        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n",
        "        \n",
        "        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
        "        errD.backward()    # 誤差逆伝播\n",
        "        optimizerD.step()   # Dのパラメーターを更新\n",
        "\n",
        "        ############################\n",
        "        # 生成器Gの更新\n",
        "        ###########################\n",
        "        netG.zero_grad()    # 勾配の初期化\n",
        "        \n",
        "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n",
        "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n",
        "        errG.backward()     # 誤差逆伝播\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        optimizerG.step()   # Gのパラメータを更新\n",
        "\n",
        "        if itr % display_interval == 0: \n",
        "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
        "                  .format(epoch + 1, n_epoch,\n",
        "                          itr + 1, len(dataloader),\n",
        "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n",
        "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
        "                              normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # 確認用画像の生成\n",
        "    ############################\n",
        "    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n",
        "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
        "                      normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # モデルの保存\n",
        "    ############################\n",
        "    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n",
        "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
        "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200][1/2260] Loss_D: 3.741 Loss_G: 18.051 D(x): 0.302 D(G(z)): -0.523/5.165\n",
            "[1/200][101/2260] Loss_D: 0.794 Loss_G: 10.855 D(x): 0.678 D(G(z)): 0.232/-2.269\n",
            "[1/200][201/2260] Loss_D: 8.137 Loss_G: 29.138 D(x): 1.111 D(G(z)): 2.790/-4.379\n",
            "[1/200][301/2260] Loss_D: 0.245 Loss_G: 1.649 D(x): 0.969 D(G(z)): 0.298/-0.268\n",
            "[1/200][401/2260] Loss_D: 0.104 Loss_G: 1.240 D(x): 0.965 D(G(z)): 0.061/-0.102\n",
            "[1/200][501/2260] Loss_D: 0.154 Loss_G: 1.120 D(x): 0.964 D(G(z)): 0.135/-0.047\n",
            "[1/200][601/2260] Loss_D: 0.235 Loss_G: 1.120 D(x): 1.012 D(G(z)): 0.234/-0.041\n",
            "[1/200][701/2260] Loss_D: 0.244 Loss_G: 0.986 D(x): 0.791 D(G(z)): 0.301/0.029\n",
            "[1/200][801/2260] Loss_D: 0.532 Loss_G: 0.492 D(x): 0.544 D(G(z)): -0.266/0.315\n",
            "[1/200][901/2260] Loss_D: 0.153 Loss_G: 0.767 D(x): 0.859 D(G(z)): 0.170/0.132\n",
            "[1/200][1001/2260] Loss_D: 0.129 Loss_G: 0.696 D(x): 0.788 D(G(z)): 0.051/0.178\n",
            "[1/200][1101/2260] Loss_D: 0.141 Loss_G: 0.761 D(x): 0.888 D(G(z)): 0.123/0.141\n",
            "[1/200][1201/2260] Loss_D: 0.235 Loss_G: 1.124 D(x): 1.099 D(G(z)): 0.392/-0.046\n",
            "[1/200][1301/2260] Loss_D: 0.136 Loss_G: 1.058 D(x): 0.875 D(G(z)): 0.026/-0.014\n",
            "[1/200][1401/2260] Loss_D: 0.188 Loss_G: 0.672 D(x): 0.671 D(G(z)): 0.031/0.199\n",
            "[1/200][1501/2260] Loss_D: 0.101 Loss_G: 0.905 D(x): 0.927 D(G(z)): 0.139/0.060\n",
            "[1/200][1601/2260] Loss_D: 0.573 Loss_G: 1.479 D(x): 1.240 D(G(z)): 0.576/-0.181\n",
            "[1/200][1701/2260] Loss_D: 0.218 Loss_G: 1.338 D(x): 1.110 D(G(z)): 0.347/-0.130\n",
            "[1/200][1801/2260] Loss_D: 0.369 Loss_G: 1.586 D(x): 0.938 D(G(z)): 0.410/-0.207\n",
            "[1/200][1901/2260] Loss_D: 0.103 Loss_G: 1.027 D(x): 0.976 D(G(z)): 0.239/-0.005\n",
            "[1/200][2001/2260] Loss_D: 0.239 Loss_G: 0.545 D(x): 0.634 D(G(z)): 0.070/0.283\n",
            "[1/200][2101/2260] Loss_D: 0.474 Loss_G: 2.031 D(x): 1.301 D(G(z)): 0.506/-0.385\n",
            "[1/200][2201/2260] Loss_D: 0.396 Loss_G: 0.252 D(x): 0.446 D(G(z)): -0.095/0.521\n",
            "[2/200][1/2260] Loss_D: 0.279 Loss_G: 1.607 D(x): 0.950 D(G(z)): 0.385/-0.250\n",
            "[2/200][101/2260] Loss_D: 0.460 Loss_G: 0.848 D(x): 0.927 D(G(z)): 0.550/0.111\n",
            "[2/200][201/2260] Loss_D: 0.336 Loss_G: 0.597 D(x): 0.602 D(G(z)): 0.104/0.251\n",
            "[2/200][301/2260] Loss_D: 0.555 Loss_G: 1.203 D(x): 0.926 D(G(z)): 0.642/-0.085\n",
            "[2/200][401/2260] Loss_D: 0.561 Loss_G: 1.299 D(x): 0.731 D(G(z)): 0.524/-0.106\n",
            "[2/200][501/2260] Loss_D: 0.398 Loss_G: 0.687 D(x): 0.514 D(G(z)): 0.149/0.190\n",
            "[2/200][601/2260] Loss_D: 0.330 Loss_G: 0.795 D(x): 0.873 D(G(z)): 0.353/0.149\n",
            "[2/200][701/2260] Loss_D: 0.215 Loss_G: 1.065 D(x): 0.843 D(G(z)): 0.237/-0.007\n",
            "[2/200][801/2260] Loss_D: 0.311 Loss_G: 1.263 D(x): 0.924 D(G(z)): 0.413/-0.107\n",
            "[2/200][901/2260] Loss_D: 0.176 Loss_G: 1.214 D(x): 0.889 D(G(z)): 0.220/-0.087\n",
            "[2/200][1001/2260] Loss_D: 0.204 Loss_G: 0.728 D(x): 0.660 D(G(z)): 0.051/0.173\n",
            "[2/200][1101/2260] Loss_D: 0.354 Loss_G: 0.656 D(x): 0.531 D(G(z)): 0.011/0.232\n",
            "[2/200][1201/2260] Loss_D: 0.299 Loss_G: 0.516 D(x): 0.564 D(G(z)): 0.151/0.298\n",
            "[2/200][1301/2260] Loss_D: 0.336 Loss_G: 0.415 D(x): 0.569 D(G(z)): 0.271/0.365\n",
            "[2/200][1401/2260] Loss_D: 0.349 Loss_G: 1.121 D(x): 1.110 D(G(z)): 0.492/-0.041\n",
            "[2/200][1501/2260] Loss_D: 0.643 Loss_G: 2.453 D(x): 1.303 D(G(z)): 0.655/-0.539\n",
            "[2/200][1601/2260] Loss_D: 0.241 Loss_G: 1.086 D(x): 0.699 D(G(z)): 0.246/-0.025\n",
            "[2/200][1701/2260] Loss_D: 0.297 Loss_G: 1.479 D(x): 0.924 D(G(z)): 0.363/-0.177\n",
            "[2/200][1801/2260] Loss_D: 0.290 Loss_G: 0.612 D(x): 0.618 D(G(z)): 0.138/0.229\n",
            "[2/200][1901/2260] Loss_D: 0.148 Loss_G: 1.127 D(x): 0.794 D(G(z)): 0.162/-0.036\n",
            "[2/200][2001/2260] Loss_D: 0.137 Loss_G: 1.200 D(x): 0.849 D(G(z)): 0.202/-0.078\n",
            "[2/200][2101/2260] Loss_D: 0.182 Loss_G: 0.794 D(x): 0.713 D(G(z)): 0.108/0.136\n",
            "[2/200][2201/2260] Loss_D: 0.134 Loss_G: 0.826 D(x): 0.787 D(G(z)): -0.070/0.104\n",
            "[3/200][1/2260] Loss_D: 0.501 Loss_G: 2.164 D(x): 1.062 D(G(z)): 0.619/-0.446\n",
            "[3/200][101/2260] Loss_D: 0.197 Loss_G: 1.164 D(x): 0.831 D(G(z)): 0.263/-0.064\n",
            "[3/200][201/2260] Loss_D: 0.550 Loss_G: 2.645 D(x): 1.315 D(G(z)): 0.611/-0.609\n",
            "[3/200][301/2260] Loss_D: 0.352 Loss_G: 0.653 D(x): 0.807 D(G(z)): 0.477/0.212\n",
            "[3/200][401/2260] Loss_D: 0.228 Loss_G: 0.681 D(x): 0.617 D(G(z)): 0.089/0.190\n",
            "[3/200][501/2260] Loss_D: 0.205 Loss_G: 1.126 D(x): 0.769 D(G(z)): 0.290/-0.049\n",
            "[3/200][601/2260] Loss_D: 0.685 Loss_G: 0.262 D(x): 0.275 D(G(z)): -0.015/0.557\n",
            "[3/200][701/2260] Loss_D: 0.608 Loss_G: 2.238 D(x): 1.098 D(G(z)): 0.724/-0.475\n",
            "[3/200][801/2260] Loss_D: 0.211 Loss_G: 0.773 D(x): 0.660 D(G(z)): 0.012/0.139\n",
            "[3/200][901/2260] Loss_D: 0.233 Loss_G: 0.998 D(x): 0.807 D(G(z)): 0.258/0.011\n",
            "[3/200][1001/2260] Loss_D: 0.232 Loss_G: 0.954 D(x): 0.742 D(G(z)): 0.221/0.045\n",
            "[3/200][1101/2260] Loss_D: 0.392 Loss_G: 0.466 D(x): 0.593 D(G(z)): -0.048/0.355\n",
            "[3/200][1201/2260] Loss_D: 0.250 Loss_G: 0.778 D(x): 0.706 D(G(z)): 0.140/0.142\n",
            "[3/200][1301/2260] Loss_D: 0.329 Loss_G: 1.238 D(x): 0.737 D(G(z)): 0.413/-0.099\n",
            "[3/200][1401/2260] Loss_D: 0.218 Loss_G: 0.610 D(x): 0.695 D(G(z)): 0.127/0.258\n",
            "[3/200][1501/2260] Loss_D: 0.216 Loss_G: 0.620 D(x): 0.644 D(G(z)): 0.045/0.235\n",
            "[3/200][1601/2260] Loss_D: 0.344 Loss_G: 0.738 D(x): 0.489 D(G(z)): 0.064/0.158\n",
            "[3/200][1701/2260] Loss_D: 0.410 Loss_G: 0.428 D(x): 0.464 D(G(z)): -0.200/0.370\n",
            "[3/200][1801/2260] Loss_D: 0.330 Loss_G: 0.595 D(x): 0.536 D(G(z)): 0.061/0.251\n",
            "[3/200][1901/2260] Loss_D: 0.684 Loss_G: 0.302 D(x): 0.320 D(G(z)): -0.193/0.488\n",
            "[3/200][2001/2260] Loss_D: 0.295 Loss_G: 1.057 D(x): 0.856 D(G(z)): 0.367/-0.007\n",
            "[3/200][2101/2260] Loss_D: 0.205 Loss_G: 1.182 D(x): 0.753 D(G(z)): 0.245/-0.076\n",
            "[3/200][2201/2260] Loss_D: 0.316 Loss_G: 1.483 D(x): 0.865 D(G(z)): 0.478/-0.206\n",
            "[4/200][1/2260] Loss_D: 0.294 Loss_G: 0.604 D(x): 0.655 D(G(z)): 0.186/0.259\n",
            "[4/200][101/2260] Loss_D: 0.296 Loss_G: 1.312 D(x): 0.810 D(G(z)): 0.430/-0.132\n",
            "[4/200][201/2260] Loss_D: 0.384 Loss_G: 0.510 D(x): 0.496 D(G(z)): 0.232/0.311\n",
            "[4/200][301/2260] Loss_D: 0.310 Loss_G: 0.742 D(x): 0.546 D(G(z)): 0.112/0.161\n",
            "[4/200][401/2260] Loss_D: 0.280 Loss_G: 1.398 D(x): 1.013 D(G(z)): 0.434/-0.168\n",
            "[4/200][501/2260] Loss_D: 0.211 Loss_G: 0.527 D(x): 0.600 D(G(z)): 0.018/0.294\n",
            "[4/200][601/2260] Loss_D: 0.390 Loss_G: 0.615 D(x): 0.484 D(G(z)): 0.133/0.231\n",
            "[4/200][701/2260] Loss_D: 0.769 Loss_G: 0.430 D(x): 0.264 D(G(z)): 0.088/0.420\n",
            "[4/200][801/2260] Loss_D: 0.298 Loss_G: 0.782 D(x): 0.584 D(G(z)): 0.224/0.134\n",
            "[4/200][901/2260] Loss_D: 0.374 Loss_G: 0.622 D(x): 0.484 D(G(z)): 0.011/0.242\n",
            "[4/200][1001/2260] Loss_D: 0.289 Loss_G: 1.076 D(x): 0.722 D(G(z)): 0.331/-0.022\n",
            "[4/200][1101/2260] Loss_D: 0.169 Loss_G: 0.870 D(x): 0.708 D(G(z)): 0.155/0.081\n",
            "[4/200][1201/2260] Loss_D: 0.761 Loss_G: 0.184 D(x): 0.231 D(G(z)): -0.196/0.618\n",
            "[4/200][1301/2260] Loss_D: 0.240 Loss_G: 1.429 D(x): 0.921 D(G(z)): 0.389/-0.183\n",
            "[4/200][1401/2260] Loss_D: 0.268 Loss_G: 0.341 D(x): 0.583 D(G(z)): 0.083/0.442\n",
            "[4/200][1501/2260] Loss_D: 0.176 Loss_G: 0.882 D(x): 0.836 D(G(z)): 0.282/0.080\n",
            "[4/200][1601/2260] Loss_D: 0.894 Loss_G: 0.156 D(x): 0.150 D(G(z)): -0.267/0.672\n",
            "[4/200][1701/2260] Loss_D: 0.172 Loss_G: 1.202 D(x): 0.806 D(G(z)): 0.203/-0.085\n",
            "[4/200][1801/2260] Loss_D: 0.255 Loss_G: 0.570 D(x): 0.693 D(G(z)): 0.267/0.260\n",
            "[4/200][1901/2260] Loss_D: 0.285 Loss_G: 0.561 D(x): 0.586 D(G(z)): 0.192/0.266\n",
            "[4/200][2001/2260] Loss_D: 0.284 Loss_G: 0.539 D(x): 0.585 D(G(z)): 0.251/0.277\n",
            "[4/200][2101/2260] Loss_D: 0.260 Loss_G: 0.773 D(x): 0.789 D(G(z)): 0.387/0.137\n",
            "[4/200][2201/2260] Loss_D: 0.202 Loss_G: 0.887 D(x): 0.669 D(G(z)): 0.157/0.068\n",
            "[5/200][1/2260] Loss_D: 0.310 Loss_G: 0.581 D(x): 0.593 D(G(z)): 0.075/0.266\n",
            "[5/200][101/2260] Loss_D: 0.342 Loss_G: 1.956 D(x): 1.095 D(G(z)): 0.494/-0.382\n",
            "[5/200][201/2260] Loss_D: 0.152 Loss_G: 0.760 D(x): 0.722 D(G(z)): 0.054/0.142\n",
            "[5/200][301/2260] Loss_D: 0.171 Loss_G: 0.716 D(x): 0.678 D(G(z)): 0.034/0.170\n",
            "[5/200][401/2260] Loss_D: 0.302 Loss_G: 0.723 D(x): 0.536 D(G(z)): 0.157/0.162\n",
            "[5/200][501/2260] Loss_D: 0.277 Loss_G: 1.172 D(x): 0.935 D(G(z)): 0.440/-0.071\n",
            "[5/200][601/2260] Loss_D: 0.206 Loss_G: 1.381 D(x): 0.909 D(G(z)): 0.316/-0.157\n",
            "[5/200][701/2260] Loss_D: 0.171 Loss_G: 0.814 D(x): 0.729 D(G(z)): -0.052/0.108\n",
            "[5/200][801/2260] Loss_D: 0.104 Loss_G: 1.125 D(x): 0.844 D(G(z)): 0.156/-0.054\n",
            "[5/200][901/2260] Loss_D: 0.168 Loss_G: 0.801 D(x): 0.897 D(G(z)): 0.283/0.117\n",
            "[5/200][1001/2260] Loss_D: 0.248 Loss_G: 1.081 D(x): 0.835 D(G(z)): 0.296/-0.029\n",
            "[5/200][1101/2260] Loss_D: 0.186 Loss_G: 0.948 D(x): 0.813 D(G(z)): 0.180/0.074\n",
            "[5/200][1201/2260] Loss_D: 0.259 Loss_G: 0.633 D(x): 0.616 D(G(z)): 0.173/0.218\n",
            "[5/200][1301/2260] Loss_D: 0.214 Loss_G: 1.200 D(x): 0.937 D(G(z)): 0.349/-0.083\n",
            "[5/200][1401/2260] Loss_D: 0.185 Loss_G: 0.681 D(x): 0.695 D(G(z)): 0.172/0.196\n",
            "[5/200][1501/2260] Loss_D: 0.249 Loss_G: 1.093 D(x): 0.845 D(G(z)): 0.391/-0.035\n",
            "[5/200][1601/2260] Loss_D: 0.212 Loss_G: 0.720 D(x): 0.748 D(G(z)): 0.156/0.167\n",
            "[5/200][1701/2260] Loss_D: 0.234 Loss_G: 1.035 D(x): 0.836 D(G(z)): 0.336/-0.007\n",
            "[5/200][1801/2260] Loss_D: 0.221 Loss_G: 0.663 D(x): 0.595 D(G(z)): 0.026/0.207\n",
            "[5/200][1901/2260] Loss_D: 0.301 Loss_G: 0.610 D(x): 0.531 D(G(z)): 0.037/0.238\n",
            "[5/200][2001/2260] Loss_D: 0.190 Loss_G: 0.957 D(x): 0.857 D(G(z)): 0.293/0.039\n",
            "[5/200][2101/2260] Loss_D: 1.123 Loss_G: 0.922 D(x): 1.031 D(G(z)): 0.922/0.182\n",
            "[5/200][2201/2260] Loss_D: 0.228 Loss_G: 0.670 D(x): 0.787 D(G(z)): 0.325/0.197\n",
            "[6/200][1/2260] Loss_D: 0.380 Loss_G: 1.127 D(x): 0.805 D(G(z)): 0.471/0.006\n",
            "[6/200][101/2260] Loss_D: 0.141 Loss_G: 0.801 D(x): 0.794 D(G(z)): 0.201/0.118\n",
            "[6/200][201/2260] Loss_D: 0.224 Loss_G: 0.651 D(x): 0.639 D(G(z)): 0.147/0.205\n",
            "[6/200][301/2260] Loss_D: 0.704 Loss_G: 0.120 D(x): 0.223 D(G(z)): -0.085/0.695\n",
            "[6/200][401/2260] Loss_D: 0.238 Loss_G: 0.588 D(x): 0.648 D(G(z)): 0.233/0.242\n",
            "[6/200][501/2260] Loss_D: 0.231 Loss_G: 0.988 D(x): 0.776 D(G(z)): 0.258/0.031\n",
            "[6/200][601/2260] Loss_D: 0.262 Loss_G: 1.197 D(x): 1.001 D(G(z)): 0.405/-0.065\n",
            "[6/200][701/2260] Loss_D: 0.248 Loss_G: 0.670 D(x): 0.619 D(G(z)): 0.145/0.195\n",
            "[6/200][801/2260] Loss_D: 0.275 Loss_G: 0.535 D(x): 0.599 D(G(z)): 0.170/0.284\n",
            "[6/200][901/2260] Loss_D: 0.301 Loss_G: 0.715 D(x): 0.636 D(G(z)): 0.298/0.164\n",
            "[6/200][1001/2260] Loss_D: 0.220 Loss_G: 0.868 D(x): 0.869 D(G(z)): 0.251/0.085\n",
            "[6/200][1101/2260] Loss_D: 0.249 Loss_G: 0.780 D(x): 0.641 D(G(z)): 0.209/0.133\n",
            "[6/200][1201/2260] Loss_D: 0.155 Loss_G: 0.720 D(x): 0.831 D(G(z)): 0.258/0.166\n",
            "[6/200][1301/2260] Loss_D: 0.140 Loss_G: 0.995 D(x): 0.796 D(G(z)): 0.166/0.010\n",
            "[6/200][1401/2260] Loss_D: 0.179 Loss_G: 0.832 D(x): 0.655 D(G(z)): 0.097/0.111\n",
            "[6/200][1501/2260] Loss_D: 0.693 Loss_G: 0.275 D(x): 0.271 D(G(z)): -0.065/0.667\n",
            "[6/200][1601/2260] Loss_D: 0.304 Loss_G: 0.628 D(x): 0.802 D(G(z)): 0.419/0.239\n",
            "[6/200][1701/2260] Loss_D: 0.270 Loss_G: 1.082 D(x): 0.877 D(G(z)): 0.396/-0.022\n",
            "[6/200][1801/2260] Loss_D: 0.342 Loss_G: 1.804 D(x): 1.125 D(G(z)): 0.493/-0.334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HnVHkaZAR7bp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}