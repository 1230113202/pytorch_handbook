{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "section6_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zpRXnZ3qcxMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #colabを使う方はこちらを使用ください。\n",
        "# !pip install torch==0.4.1\n",
        "# !pip install torchvision==0.2.1\n",
        "# !pip install numpy==1.14.6\n",
        "# !pip install matplotlib==2.1.2\n",
        "# !pip install pillow==5.0.0\n",
        "# !pip install opencv-python==3.4.3.18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1YT56IaUp7D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): \n",
        "    Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "    for extension in extensions: \n",
        "        register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11FPu6O9dAjw",
        "colab_type": "code",
        "outputId": "2d304ae3-4211-4ed0-bbf3-7811d2be3af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "#Google Driveにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MIOat2A3dH7m",
        "colab_type": "code",
        "outputId": "3deafddd-70ee-4ef9-9f01-16f0fa422bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。※変更の必要がある場合はパスを変更してください。\n",
        "cd /content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "34z3rH24dKhu",
        "colab_type": "code",
        "outputId": "ad0b11c7-6992-4980-9c03-5b247376e66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#colabを使う方はこちらを使用ください。\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net.py\t     result_cgan   section6_3.ipynb  train_cgan.py\n",
            "__pycache__  result_lsgan  section6_4.ipynb  train_lsgan.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pKAU9MdKEGRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from net import weights_init, Generator, Discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDBmvWisEGRy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def onehot_encode(label, device, n_class=10):\n",
        "    \"\"\"\n",
        "    カテゴリカル変数のラベルをOne-Hoe形式に変換する\n",
        "    :param label: 変換対象のラベル\n",
        "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
        "    :param n_class: ラベルのクラス数\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    eye = torch.eye(n_class, device=device)\n",
        "    # ランダムベクトルあるいは画像と連結するために(B, c_class, 1, 1)のTensorにして戻す\n",
        "    return eye[label].view(-1, n_class, 1, 1)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GO9cyPyNEGR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concat_image_label(image, label, device, n_class=10):\n",
        "    \"\"\"\n",
        "    画像とラベルを連結する\n",
        "    :param image:　画像\n",
        "    :param label: ラベル\n",
        "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
        "    :param n_class: ラベルのクラス数\n",
        "    :return:　画像とラベルをチャネル方向に連結したTensor\n",
        "    \"\"\"\n",
        "    B, C, H, W = image.shape    # 画像Tensorの大きさを取得\n",
        "    \n",
        "    oh_label = onehot_encode(label, device)         # ラベルをOne-Hotベクトル化\n",
        "    oh_label = oh_label.expand(B, n_class, H, W)    # 画像のサイズに合わせるようラベルを拡張する\n",
        "    return torch.cat((image, oh_label), dim=1)      # 画像とラベルをチャネル方向（dim=1）で連結する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVRqLztIEGR3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concat_noise_label(noise, label, device):\n",
        "    \"\"\"\n",
        "    ノイズ（ランダムベクトル）とラベルを連結する\n",
        "    :param noise: ノイズ\n",
        "    :param label: ラベル\n",
        "    :param device: 学習に使用するデバイス。CPUあるいはGPU\n",
        "    :return:　ノイズとラベルを連結したTensor\n",
        "    \"\"\"\n",
        "    oh_label = onehot_encode(label, device)     # ラベルをOne-Hotベクトル化\n",
        "    return torch.cat((noise, oh_label), dim=1)  # ノイズとラベルをチャネル方向（dim=1）で連結する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylkPJXzgEGR6",
        "colab_type": "code",
        "outputId": "f7ba264c-84b0-49fb-ebaf-b94b2932741c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "workers = 2\n",
        "batch_size = 50\n",
        "nz = 100\n",
        "nch_g = 64\n",
        "nch_d = 64\n",
        "n_epoch = 200\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "outf = './result_cgan'\n",
        "display_interval = 100\n",
        "\n",
        "try:\n",
        "    os.makedirs(outf)\n",
        "except OSError:\n",
        "    pass\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f255b77c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "TXYnAcifEGR8",
        "colab_type": "code",
        "outputId": "2cf21b72-4482-416b-9258-3d8c82102fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "trainset = dset.STL10(root='../../dataset/stl10_root', download=True, split='train',\n",
        "                      transform=transforms.Compose([\n",
        "                          transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                      ]))   # ラベルを使用するのでunlabeledを含めない\n",
        "testset = dset.STL10(root='../../dataset/stl10_root', download=True, split='test',\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                         transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                     ]))\n",
        "dataset = trainset + testset\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZYz-08POEGR_",
        "colab_type": "code",
        "outputId": "e7b52fe6-f232-4e94-be97-352fcb7d711f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "# 生成器G。ランダムベクトルとラベルを連結したベクトルから贋作画像を生成する\n",
        "netG = Generator(nz=nz+10, nch_g=nch_g).to(device)   # 入力ベクトルの次元は、ランダムベクトルの次元nzにクラス数10を加算したもの\n",
        "netG.apply(weights_init)\n",
        "print(netG)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): ConvTranspose2d(110, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSc1GjkIEGSC",
        "colab_type": "code",
        "outputId": "58e6a33c-08ca-4741-86b8-a08b4e049efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "# 識別器D。画像とラベルを連結したTensorが、元画像か贋作画像かを識別する\n",
        "netD = Discriminator(nch=3+10, nch_d=nch_d).to(device)   # 入力Tensorのチャネル数は、画像のチャネル数3にクラス数10を加算したもの\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): Conv2d(13, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WIOjtuvSEGSG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "\n",
        "fixed_label = [i for i in range(10)] * (batch_size // 10)  # 確認用のラベル。0〜9のラベルの繰り返し\n",
        "fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n",
        "\n",
        "fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device)  # 確認用のノイズとラベルを連結"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4unIheuEGSJ",
        "colab_type": "code",
        "outputId": "adbe6e41-0710-4458-bc18-9ed7c4d8ac43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "# 学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "    for itr, data in enumerate(dataloader):\n",
        "        real_image = data[0].to(device)     # 元画像\n",
        "        real_label = data[1].to(device)     # 元画像に対応するラベル\n",
        "        real_image_label = concat_image_label(real_image, real_label, device)   # 元画像とラベルを連結\n",
        "\n",
        "        sample_size = real_image.size(0)\n",
        "        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n",
        "        fake_label = torch.randint(10, (sample_size,), dtype=torch.long, device=device)     # 贋作画像生成用のラベル\n",
        "        fake_noise_label = concat_noise_label(noise, fake_label, device)    # ノイズとラベルを連結\n",
        "        \n",
        "        real_target = torch.full((sample_size,), 1., device=device)\n",
        "        fake_target = torch.full((sample_size,), 0., device=device)\n",
        "\n",
        "        ############################\n",
        "        # 識別器Dの更新\n",
        "        ###########################\n",
        "        netD.zero_grad()\n",
        "\n",
        "        output = netD(real_image_label)     # 識別器Dで元画像とラベルの組み合わせに対する識別信号を出力\n",
        "        errD_real = criterion(output, real_target)        \n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        fake_image = netG(fake_noise_label)     # 生成器Gでラベルに対応した贋作画像を生成\n",
        "        fake_image_label = concat_image_label(fake_image, fake_label, device)   # 贋作画像とラベルを連結\n",
        "\n",
        "        output = netD(fake_image_label.detach())    # 識別器Dで贋作画像とラベルの組み合わせに対する識別信号を出力\n",
        "        errD_fake = criterion(output, fake_target)\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        errD.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # 生成器Gの更新\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        \n",
        "        output = netD(fake_image_label)     # 更新した識別器Dで改めて贋作画像とラベルの組み合わせに対する識別信号を出力\n",
        "        errG = criterion(output, real_target)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        \n",
        "        optimizerG.step()\n",
        "\n",
        "        if itr % display_interval == 0:\n",
        "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
        "                  .format(epoch + 1, n_epoch,\n",
        "                          itr + 1, len(dataloader),\n",
        "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        if epoch == 0 and itr == 0:\n",
        "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
        "                              normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # 確認用画像の生成\n",
        "    ############################\n",
        "    fake_image = netG(fixed_noise_label)    # 1エポック終了ごとに、指定したラベルに対応する贋作画像を生成する\n",
        "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
        "                      normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # モデルの保存\n",
        "    ############################\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
        "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200][1/260] Loss_D: 1.958 Loss_G: 31.280 D(x): 0.480 D(G(z)): 0.105/1.759\n",
            "[1/200][101/260] Loss_D: 0.561 Loss_G: 0.672 D(x): 0.649 D(G(z)): -0.204/0.255\n",
            "[1/200][201/260] Loss_D: 0.429 Loss_G: 0.572 D(x): 0.635 D(G(z)): 0.191/0.299\n",
            "[2/200][1/260] Loss_D: 0.570 Loss_G: 1.178 D(x): 0.707 D(G(z)): 0.347/-0.015\n",
            "[2/200][101/260] Loss_D: 0.681 Loss_G: 0.720 D(x): 0.578 D(G(z)): 0.526/0.223\n",
            "[2/200][201/260] Loss_D: 0.129 Loss_G: 1.191 D(x): 0.963 D(G(z)): -0.011/-0.083\n",
            "[3/200][1/260] Loss_D: 0.136 Loss_G: 0.874 D(x): 0.921 D(G(z)): -0.030/0.082\n",
            "[3/200][101/260] Loss_D: 0.266 Loss_G: 0.780 D(x): 0.778 D(G(z)): 0.269/0.138\n",
            "[3/200][201/260] Loss_D: 0.841 Loss_G: 0.673 D(x): 0.326 D(G(z)): -0.011/0.318\n",
            "[4/200][1/260] Loss_D: 0.320 Loss_G: 0.618 D(x): 0.651 D(G(z)): 0.255/0.252\n",
            "[4/200][101/260] Loss_D: 0.787 Loss_G: 0.906 D(x): 0.683 D(G(z)): 0.533/0.137\n",
            "[4/200][201/260] Loss_D: 0.321 Loss_G: 0.655 D(x): 0.750 D(G(z)): 0.398/0.217\n",
            "[5/200][1/260] Loss_D: 0.520 Loss_G: 0.510 D(x): 0.672 D(G(z)): 0.428/0.341\n",
            "[5/200][101/260] Loss_D: 0.636 Loss_G: 0.838 D(x): 0.662 D(G(z)): 0.634/0.122\n",
            "[5/200][201/260] Loss_D: 0.609 Loss_G: 0.496 D(x): 0.422 D(G(z)): 0.291/0.379\n",
            "[6/200][1/260] Loss_D: 0.365 Loss_G: 0.501 D(x): 0.502 D(G(z)): 0.130/0.308\n",
            "[6/200][101/260] Loss_D: 0.424 Loss_G: 0.606 D(x): 0.575 D(G(z)): 0.359/0.241\n",
            "[6/200][201/260] Loss_D: 0.494 Loss_G: 0.327 D(x): 0.434 D(G(z)): 0.332/0.464\n",
            "[7/200][1/260] Loss_D: 0.498 Loss_G: 0.693 D(x): 0.586 D(G(z)): 0.480/0.188\n",
            "[7/200][101/260] Loss_D: 0.381 Loss_G: 0.648 D(x): 0.688 D(G(z)): 0.424/0.219\n",
            "[7/200][201/260] Loss_D: 0.494 Loss_G: 0.756 D(x): 0.644 D(G(z)): 0.485/0.149\n",
            "[8/200][1/260] Loss_D: 0.396 Loss_G: 0.423 D(x): 0.482 D(G(z)): 0.248/0.372\n",
            "[8/200][101/260] Loss_D: 0.388 Loss_G: 0.604 D(x): 0.786 D(G(z)): 0.530/0.237\n",
            "[8/200][201/260] Loss_D: 0.481 Loss_G: 0.455 D(x): 0.549 D(G(z)): 0.391/0.357\n",
            "[9/200][1/260] Loss_D: 0.489 Loss_G: 0.643 D(x): 0.459 D(G(z)): 0.326/0.229\n",
            "[9/200][101/260] Loss_D: 0.640 Loss_G: 0.658 D(x): 0.680 D(G(z)): 0.575/0.255\n",
            "[9/200][201/260] Loss_D: 0.288 Loss_G: 0.676 D(x): 0.633 D(G(z)): 0.306/0.190\n",
            "[10/200][1/260] Loss_D: 0.637 Loss_G: 1.015 D(x): 0.725 D(G(z)): 0.707/0.008\n",
            "[10/200][101/260] Loss_D: 0.455 Loss_G: 0.376 D(x): 0.509 D(G(z)): 0.369/0.401\n",
            "[10/200][201/260] Loss_D: 0.593 Loss_G: 0.601 D(x): 0.594 D(G(z)): 0.382/0.318\n",
            "[11/200][1/260] Loss_D: 0.368 Loss_G: 0.567 D(x): 0.637 D(G(z)): 0.373/0.276\n",
            "[11/200][101/260] Loss_D: 0.406 Loss_G: 0.565 D(x): 0.711 D(G(z)): 0.499/0.265\n",
            "[11/200][201/260] Loss_D: 0.550 Loss_G: 0.473 D(x): 0.380 D(G(z)): 0.254/0.325\n",
            "[12/200][1/260] Loss_D: 0.526 Loss_G: 0.346 D(x): 0.374 D(G(z)): 0.120/0.436\n",
            "[12/200][101/260] Loss_D: 0.562 Loss_G: 0.749 D(x): 0.748 D(G(z)): 0.587/0.196\n",
            "[12/200][201/260] Loss_D: 0.368 Loss_G: 0.566 D(x): 0.596 D(G(z)): 0.385/0.261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D1PemeWySvW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}