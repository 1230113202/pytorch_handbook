{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section5_4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HeC1svlM-R7I","colab_type":"code","colab":{}},"cell_type":"code","source":["# #colabを使う方はこちらを使用ください。\n","# !pip install torch==0.4.1\n","# !pip install torchvision==0.2.1\n","# !pip install numpy==1.14.6\n","# !pip install matplotlib==2.1.2\n","# !pip install pillow==5.0.0\n","# !pip install opencv-python==3.4.3.18\n","# !pip install torchtext==0.3.1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7_OZ39yC_46j","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget --quiet --continue http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n","!tar -xzf simple-examples.tgz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eDBr8PLFAAc9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"0dcc5b0b-c2c6-4cb7-acb3-4eb3751fbc8d","executionInfo":{"status":"ok","timestamp":1540689458437,"user_tz":-540,"elapsed":2400,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["!ls simple-examples"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1-train\t\t   5-one-iter\t\t       9-char-based-lm\ttemp\n","2-nbest-rescore    6-recovery-during-training  data\n","3-combination\t   7-dynamic-evaluation        models\n","4-data-generation  8-direct\t\t       rnnlm-0.2b\n"],"name":"stdout"}]},{"metadata":{"id":"QhAWbKUUARRD","colab_type":"code","colab":{}},"cell_type":"code","source":["!mv ./simple-examples/data/ptb.train.txt train.txt\n","!mv ./simple-examples/data/ptb.valid.txt valid.txt\n","!mv ./simple-examples/data/ptb.test.txt test.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LEDrpxlDAZLW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"5f3ecb8b-243a-4ef3-eb90-757464eea50e","executionInfo":{"status":"ok","timestamp":1540689464669,"user_tz":-540,"elapsed":2079,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["data\t\t      net.ckpt\t       simple-examples.tgz  valid.txt\n","hymenoptera_data      sample_data      test.txt\n","hymenoptera_data.zip  simple-examples  train.txt\n"],"name":"stdout"}]},{"metadata":{"id":"n1UMMbciAeIm","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext import data\n","from torchtext import vocab\n","from torchtext import datasets\n","\n","%matplotlib inline\n","import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M5NOEqmsAeSH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b947b1fd-1592-44fb-ae10-e5954cb3a909","executionInfo":{"status":"ok","timestamp":1540690400263,"user_tz":-540,"elapsed":501,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["# データとモデルに.to(device)を指定してgpuの計算資源を使用する。\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"14EADkKAQc6U","colab_type":"text"},"cell_type":"markdown","source":["#文章生成"]},{"metadata":{"id":"soKa-e9tQfJ1","colab_type":"text"},"cell_type":"markdown","source":["## データの読み込み"]},{"metadata":{"id":"tatmAOVUAeVl","colab_type":"code","colab":{}},"cell_type":"code","source":["# 前処理用の機能のFieldをセットアップ\n","#Field\n","TEXT = data.Field(batch_first=True)\n","#LabelField\n","LABEL = data.LabelField()\n","# データを取得\n","train_dataset, val_dataset, test_dataset = datasets.LanguageModelingDataset.splits(path=\".\"\n","                                        , train=\"train.txt\"\n","                                        , validation=\"valid.txt\"\n","                                        , test=\"test.txt\"\n","                                        , text_field=TEXT)\n","\n","TEXT.build_vocab(train_dataset, vectors=vocab.GloVe(name='6B', dim=300))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WR8xqHw8GajP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"e99c388b-a512-4893-d4aa-593789de1935","executionInfo":{"status":"ok","timestamp":1540690424108,"user_tz":-540,"elapsed":608,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["#全単語数\n","vocab_size = len(TEXT.vocab)\n","print(vocab_size)\n","# 単語の件数のtop10\n","print(TEXT.vocab.freqs.most_common(10))\n","# 単語\n","print(TEXT.vocab.itos[:10])\n","\n","#埋め込みベクトルを取得\n","word_embeddings = TEXT.vocab.vectors\n","# ハイパーパラメータ\n","embedding_length = 300\n","hidden_size = 256\n","batch_size = 32"],"execution_count":11,"outputs":[{"output_type":"stream","text":["10001\n","[('the', 50770), ('<unk>', 45020), ('<eos>', 42068), ('N', 32481), ('of', 24400), ('to', 23638), ('a', 21196), ('in', 18000), ('and', 17474), (\"'s\", 9784)]\n","['<unk>', '<pad>', 'the', '<eos>', 'N', 'of', 'to', 'a', 'in', 'and']\n"],"name":"stdout"}]},{"metadata":{"id":"P3RbA_s1Ah3O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"25a9dc0a-578b-4026-88e9-202a3c813227","executionInfo":{"status":"ok","timestamp":1540690424981,"user_tz":-540,"elapsed":496,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["# BPTTIteratorは言語モデル用のイテレータ作成を行います。\n","# textとtarget属性を持ちます。\n","train_iter, val_iter, test_iter = data.BPTTIterator.splits((train_dataset, val_dataset, test_dataset)\n","                                                           , batch_size=32,  bptt_len=30, repeat=False)\n","\n","print(len(train_iter))\n","print(len(val_iter))\n","print(len(test_iter))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["969\n","77\n","86\n"],"name":"stdout"}]},{"metadata":{"id":"nImqWKVbAh6d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":332},"outputId":"37c0a615-3240-49ba-c447-b5f34511c431","executionInfo":{"status":"ok","timestamp":1540690425754,"user_tz":-540,"elapsed":639,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["for i, train in enumerate(train_iter):\n","    print(\"データの形状確認\")\n","    print(train.text.size())\n","    print(train.target.size())\n","    print(\"permuteでバッチを先にする\")\n","    print(train.text.permute(1, 0).size())\n","    print(train.target.permute(1, 0).size())\n","    print(\"１データ目の形状とデータを確認\")\n","    text = train.text.permute(1, 0)\n","    target = train.target.permute(1, 0)\n","    print(text[0,:].size())\n","    print(target[0,:].size())\n","    print(text[0,:].tolist())\n","    print(target[0,:].tolist())\n","    print(\"１データ目の単語列を表示\")\n","    print([TEXT.vocab.itos[data] for data in  text[0,:].tolist()])\n","    print([TEXT.vocab.itos[data] for data in  target[0,:].tolist()])\n","    print(\"２データ目の単語列を表示\")\n","    print([TEXT.vocab.itos[data] for data in  text[1,:].tolist()])\n","    print([TEXT.vocab.itos[data] for data in  target[1,:].tolist()])\n","            \n","    break"],"execution_count":13,"outputs":[{"output_type":"stream","text":["データの形状確認\n","torch.Size([30, 32])\n","torch.Size([30, 32])\n","permuteでバッチを先にする\n","torch.Size([32, 30])\n","torch.Size([32, 30])\n","１データ目の形状とデータを確認\n","torch.Size([30])\n","torch.Size([30])\n","[9971, 9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987, 9988, 9989, 9990, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 3, 9257, 0, 4, 73, 394]\n","[9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987, 9988, 9989, 9990, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 3, 9257, 0, 4, 73, 394, 34]\n","１データ目の単語列を表示\n","['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old']\n","['banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will']\n","２データ目の単語列を表示\n","['company', 'will', 'begin', 'mailing', 'materials', 'to', 'shareholders', 'at', 'the', 'end', 'of', 'this', 'week', '<eos>', 'under', 'the', 'offer', 'shareholders', 'will', 'receive', 'one', 'right', 'for', 'each', 'N', 'common', 'shares', 'owned', '<eos>', 'each']\n","['will', 'begin', 'mailing', 'materials', 'to', 'shareholders', 'at', 'the', 'end', 'of', 'this', 'week', '<eos>', 'under', 'the', 'offer', 'shareholders', 'will', 'receive', 'one', 'right', 'for', 'each', 'N', 'common', 'shares', 'owned', '<eos>', 'each', 'right']\n"],"name":"stdout"}]},{"metadata":{"id":"7F6l4OjQQlFC","colab_type":"text"},"cell_type":"markdown","source":["## ネットワークを定義"]},{"metadata":{"id":"XMj7HAguLNqS","colab_type":"code","colab":{}},"cell_type":"code","source":["class LstmLangModel(nn.Module):\n","    def __init__(self, batch_size, hidden_size, vocab_size, embedding_length, weights):\n","        super(LstmLangModel, self).__init__()\n","        self.batch_size = batch_size\n","        self.hidden_size = hidden_size\n","        self.vocab_size = vocab_size\n","        self.embed = nn.Embedding(vocab_size, embedding_length)\n","        self.embed.weight.data.copy_(weights)\n","        self.lstm = nn.LSTM(embedding_length, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","    \n","    def forward(self, x, h):\n","        x = self.embed(x)\n","        output_seq, (h, c) = self.lstm(x, h)\n","        # 出力を変形する (batch_size*sequence_length, 隠れ層のユニット数hidden_size)\n","        out = output_seq.reshape(output_seq.size(0)*output_seq.size(1), output_seq.size(2))\n","        out = self.fc(out) \n","        return out, (h, c)\n","\n","net = LstmLangModel(batch_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n","net = net.to(device)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ht_4zbkmNZF7","colab_type":"code","colab":{}},"cell_type":"code","source":["# 損失関数、最適化関数を定義\n","criterion = nn.CrossEntropyLoss()\n","optim = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-XD9DCP8QnhC","colab_type":"text"},"cell_type":"markdown","source":["## 学習"]},{"metadata":{"id":"8l2u4A-YNcri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3484},"outputId":"e2be5299-39f2-470f-ed0e-506b93bf3ba8","executionInfo":{"status":"ok","timestamp":1540695061335,"user_tz":-540,"elapsed":4631306,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["num_epochs = 200\n","train_loss_list = []\n","\n","# Truncated backpropagation\n","# 逆伝播を途中で打ち切る\n","def detach(states):\n","    return [state.detach() for state in states] \n","\n","for epoch in range(num_epochs):\n","    train_loss = 0\n","    # 初期隠れ状態とセル状態を設定する\n","    states = (torch.zeros(1, batch_size, hidden_size).to(device),\n","              torch.zeros(1, batch_size, hidden_size).to(device))\n","    #train\n","    net.train()\n","    for i, batch in enumerate(train_iter):\n","      text = batch.text.to(device)\n","      labels = batch.target.to(device)\n","      text = text.permute(1, 0)\n","      labels = labels.permute(1, 0)\n","      \n","      optim.zero_grad()\n","      states = detach(states)\n","      outputs, states = net(text, states)\n","      loss = criterion(outputs, labels.reshape(-1))\n","      train_loss += loss.item()\n","      loss.backward()\n","      optim.step()\n","    avg_train_loss = train_loss / len(train_iter)\n","    print ('Epoch [{}/{}], Loss: {loss:.4f}, Perplexity: {perp:5.2f}' \n","                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, perp=np.exp(avg_train_loss)))\n","    train_loss_list.append(avg_train_loss)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch [1/200], Loss: 5.8195, Perplexity: 336.80\n","Epoch [2/200], Loss: 5.0890, Perplexity: 162.23\n","Epoch [3/200], Loss: 4.7741, Perplexity: 118.41\n","Epoch [4/200], Loss: 4.5454, Perplexity: 94.20\n","Epoch [5/200], Loss: 4.3678, Perplexity: 78.87\n","Epoch [6/200], Loss: 4.2200, Perplexity: 68.03\n","Epoch [7/200], Loss: 4.0909, Perplexity: 59.79\n","Epoch [8/200], Loss: 3.9750, Perplexity: 53.25\n","Epoch [9/200], Loss: 3.8689, Perplexity: 47.89\n","Epoch [10/200], Loss: 3.7709, Perplexity: 43.42\n","Epoch [11/200], Loss: 3.6802, Perplexity: 39.66\n","Epoch [12/200], Loss: 3.5959, Perplexity: 36.45\n","Epoch [13/200], Loss: 3.5156, Perplexity: 33.63\n","Epoch [14/200], Loss: 3.4387, Perplexity: 31.14\n","Epoch [15/200], Loss: 3.3648, Perplexity: 28.93\n","Epoch [16/200], Loss: 3.2952, Perplexity: 26.98\n","Epoch [17/200], Loss: 3.2301, Perplexity: 25.28\n","Epoch [18/200], Loss: 3.1691, Perplexity: 23.79\n","Epoch [19/200], Loss: 3.1110, Perplexity: 22.44\n","Epoch [20/200], Loss: 3.0552, Perplexity: 21.22\n","Epoch [21/200], Loss: 3.0008, Perplexity: 20.10\n","Epoch [22/200], Loss: 2.9488, Perplexity: 19.08\n","Epoch [23/200], Loss: 2.8983, Perplexity: 18.14\n","Epoch [24/200], Loss: 2.8499, Perplexity: 17.29\n","Epoch [25/200], Loss: 2.8044, Perplexity: 16.52\n","Epoch [26/200], Loss: 2.7610, Perplexity: 15.82\n","Epoch [27/200], Loss: 2.7195, Perplexity: 15.17\n","Epoch [28/200], Loss: 2.6802, Perplexity: 14.59\n","Epoch [29/200], Loss: 2.6432, Perplexity: 14.06\n","Epoch [30/200], Loss: 2.6079, Perplexity: 13.57\n","Epoch [31/200], Loss: 2.5731, Perplexity: 13.11\n","Epoch [32/200], Loss: 2.5395, Perplexity: 12.67\n","Epoch [33/200], Loss: 2.5070, Perplexity: 12.27\n","Epoch [34/200], Loss: 2.4755, Perplexity: 11.89\n","Epoch [35/200], Loss: 2.4458, Perplexity: 11.54\n","Epoch [36/200], Loss: 2.4143, Perplexity: 11.18\n","Epoch [37/200], Loss: 2.3862, Perplexity: 10.87\n","Epoch [38/200], Loss: 2.3584, Perplexity: 10.57\n","Epoch [39/200], Loss: 2.3303, Perplexity: 10.28\n","Epoch [40/200], Loss: 2.3038, Perplexity: 10.01\n","Epoch [41/200], Loss: 2.2795, Perplexity:  9.77\n","Epoch [42/200], Loss: 2.2562, Perplexity:  9.55\n","Epoch [43/200], Loss: 2.2344, Perplexity:  9.34\n","Epoch [44/200], Loss: 2.2134, Perplexity:  9.15\n","Epoch [45/200], Loss: 2.1923, Perplexity:  8.96\n","Epoch [46/200], Loss: 2.1727, Perplexity:  8.78\n","Epoch [47/200], Loss: 2.1541, Perplexity:  8.62\n","Epoch [48/200], Loss: 2.1347, Perplexity:  8.45\n","Epoch [49/200], Loss: 2.1172, Perplexity:  8.31\n","Epoch [50/200], Loss: 2.1004, Perplexity:  8.17\n","Epoch [51/200], Loss: 2.0833, Perplexity:  8.03\n","Epoch [52/200], Loss: 2.0674, Perplexity:  7.90\n","Epoch [53/200], Loss: 2.0521, Perplexity:  7.78\n","Epoch [54/200], Loss: 2.0386, Perplexity:  7.68\n","Epoch [55/200], Loss: 2.0219, Perplexity:  7.55\n","Epoch [56/200], Loss: 2.0081, Perplexity:  7.45\n","Epoch [57/200], Loss: 1.9927, Perplexity:  7.34\n","Epoch [58/200], Loss: 1.9798, Perplexity:  7.24\n","Epoch [59/200], Loss: 1.9672, Perplexity:  7.15\n","Epoch [60/200], Loss: 1.9530, Perplexity:  7.05\n","Epoch [61/200], Loss: 1.9416, Perplexity:  6.97\n","Epoch [62/200], Loss: 1.9289, Perplexity:  6.88\n","Epoch [63/200], Loss: 1.9183, Perplexity:  6.81\n","Epoch [64/200], Loss: 1.9075, Perplexity:  6.74\n","Epoch [65/200], Loss: 1.8989, Perplexity:  6.68\n","Epoch [66/200], Loss: 1.8857, Perplexity:  6.59\n","Epoch [67/200], Loss: 1.8731, Perplexity:  6.51\n","Epoch [68/200], Loss: 1.8654, Perplexity:  6.46\n","Epoch [69/200], Loss: 1.8551, Perplexity:  6.39\n","Epoch [70/200], Loss: 1.8485, Perplexity:  6.35\n","Epoch [71/200], Loss: 1.8389, Perplexity:  6.29\n","Epoch [72/200], Loss: 1.8278, Perplexity:  6.22\n","Epoch [73/200], Loss: 1.8192, Perplexity:  6.17\n","Epoch [74/200], Loss: 1.8117, Perplexity:  6.12\n","Epoch [75/200], Loss: 1.8041, Perplexity:  6.07\n","Epoch [76/200], Loss: 1.7970, Perplexity:  6.03\n","Epoch [77/200], Loss: 1.7888, Perplexity:  5.98\n","Epoch [78/200], Loss: 1.7804, Perplexity:  5.93\n","Epoch [79/200], Loss: 1.7739, Perplexity:  5.89\n","Epoch [80/200], Loss: 1.7676, Perplexity:  5.86\n","Epoch [81/200], Loss: 1.7590, Perplexity:  5.81\n","Epoch [82/200], Loss: 1.7523, Perplexity:  5.77\n","Epoch [83/200], Loss: 1.7441, Perplexity:  5.72\n","Epoch [84/200], Loss: 1.7362, Perplexity:  5.68\n","Epoch [85/200], Loss: 1.7326, Perplexity:  5.66\n","Epoch [86/200], Loss: 1.7253, Perplexity:  5.61\n","Epoch [87/200], Loss: 1.7216, Perplexity:  5.59\n","Epoch [88/200], Loss: 1.7159, Perplexity:  5.56\n","Epoch [89/200], Loss: 1.7107, Perplexity:  5.53\n","Epoch [90/200], Loss: 1.7035, Perplexity:  5.49\n","Epoch [91/200], Loss: 1.6958, Perplexity:  5.45\n","Epoch [92/200], Loss: 1.6915, Perplexity:  5.43\n","Epoch [93/200], Loss: 1.6877, Perplexity:  5.41\n","Epoch [94/200], Loss: 1.6823, Perplexity:  5.38\n","Epoch [95/200], Loss: 1.6747, Perplexity:  5.34\n","Epoch [96/200], Loss: 1.6687, Perplexity:  5.31\n","Epoch [97/200], Loss: 1.6676, Perplexity:  5.30\n","Epoch [98/200], Loss: 1.6668, Perplexity:  5.30\n","Epoch [99/200], Loss: 1.6589, Perplexity:  5.25\n","Epoch [100/200], Loss: 1.6517, Perplexity:  5.22\n","Epoch [101/200], Loss: 1.6464, Perplexity:  5.19\n","Epoch [102/200], Loss: 1.6415, Perplexity:  5.16\n","Epoch [103/200], Loss: 1.6422, Perplexity:  5.17\n","Epoch [104/200], Loss: 1.6332, Perplexity:  5.12\n","Epoch [105/200], Loss: 1.6303, Perplexity:  5.11\n","Epoch [106/200], Loss: 1.6238, Perplexity:  5.07\n","Epoch [107/200], Loss: 1.6183, Perplexity:  5.04\n","Epoch [108/200], Loss: 1.6145, Perplexity:  5.03\n","Epoch [109/200], Loss: 1.6151, Perplexity:  5.03\n","Epoch [110/200], Loss: 1.6117, Perplexity:  5.01\n","Epoch [111/200], Loss: 1.6048, Perplexity:  4.98\n","Epoch [112/200], Loss: 1.6004, Perplexity:  4.96\n","Epoch [113/200], Loss: 1.5969, Perplexity:  4.94\n","Epoch [114/200], Loss: 1.5943, Perplexity:  4.92\n","Epoch [115/200], Loss: 1.5891, Perplexity:  4.90\n","Epoch [116/200], Loss: 1.5876, Perplexity:  4.89\n","Epoch [117/200], Loss: 1.5854, Perplexity:  4.88\n","Epoch [118/200], Loss: 1.5787, Perplexity:  4.85\n","Epoch [119/200], Loss: 1.5750, Perplexity:  4.83\n","Epoch [120/200], Loss: 1.5712, Perplexity:  4.81\n","Epoch [121/200], Loss: 1.5672, Perplexity:  4.79\n","Epoch [122/200], Loss: 1.5662, Perplexity:  4.79\n","Epoch [123/200], Loss: 1.5648, Perplexity:  4.78\n","Epoch [124/200], Loss: 1.5601, Perplexity:  4.76\n","Epoch [125/200], Loss: 1.5558, Perplexity:  4.74\n","Epoch [126/200], Loss: 1.5571, Perplexity:  4.74\n","Epoch [127/200], Loss: 1.5510, Perplexity:  4.72\n","Epoch [128/200], Loss: 1.5443, Perplexity:  4.68\n","Epoch [129/200], Loss: 1.5402, Perplexity:  4.67\n","Epoch [130/200], Loss: 1.5415, Perplexity:  4.67\n","Epoch [131/200], Loss: 1.5397, Perplexity:  4.66\n","Epoch [132/200], Loss: 1.5377, Perplexity:  4.65\n","Epoch [133/200], Loss: 1.5349, Perplexity:  4.64\n","Epoch [134/200], Loss: 1.5283, Perplexity:  4.61\n","Epoch [135/200], Loss: 1.5260, Perplexity:  4.60\n","Epoch [136/200], Loss: 1.5244, Perplexity:  4.59\n","Epoch [137/200], Loss: 1.5244, Perplexity:  4.59\n","Epoch [138/200], Loss: 1.5165, Perplexity:  4.56\n","Epoch [139/200], Loss: 1.5135, Perplexity:  4.54\n","Epoch [140/200], Loss: 1.5167, Perplexity:  4.56\n","Epoch [141/200], Loss: 1.5121, Perplexity:  4.54\n","Epoch [142/200], Loss: 1.5105, Perplexity:  4.53\n","Epoch [143/200], Loss: 1.5058, Perplexity:  4.51\n","Epoch [144/200], Loss: 1.5007, Perplexity:  4.49\n","Epoch [145/200], Loss: 1.4998, Perplexity:  4.48\n","Epoch [146/200], Loss: 1.4981, Perplexity:  4.47\n","Epoch [147/200], Loss: 1.4950, Perplexity:  4.46\n","Epoch [148/200], Loss: 1.4928, Perplexity:  4.45\n","Epoch [149/200], Loss: 1.4922, Perplexity:  4.45\n","Epoch [150/200], Loss: 1.4892, Perplexity:  4.43\n","Epoch [151/200], Loss: 1.4842, Perplexity:  4.41\n","Epoch [152/200], Loss: 1.4882, Perplexity:  4.43\n","Epoch [153/200], Loss: 1.4870, Perplexity:  4.42\n","Epoch [154/200], Loss: 1.4832, Perplexity:  4.41\n","Epoch [155/200], Loss: 1.4846, Perplexity:  4.41\n","Epoch [156/200], Loss: 1.4773, Perplexity:  4.38\n","Epoch [157/200], Loss: 1.4723, Perplexity:  4.36\n","Epoch [158/200], Loss: 1.4762, Perplexity:  4.38\n","Epoch [159/200], Loss: 1.4731, Perplexity:  4.36\n","Epoch [160/200], Loss: 1.4672, Perplexity:  4.34\n","Epoch [161/200], Loss: 1.4638, Perplexity:  4.32\n","Epoch [162/200], Loss: 1.4671, Perplexity:  4.34\n","Epoch [163/200], Loss: 1.4625, Perplexity:  4.32\n","Epoch [164/200], Loss: 1.4583, Perplexity:  4.30\n","Epoch [165/200], Loss: 1.4573, Perplexity:  4.29\n","Epoch [166/200], Loss: 1.4601, Perplexity:  4.31\n","Epoch [167/200], Loss: 1.4545, Perplexity:  4.28\n","Epoch [168/200], Loss: 1.4535, Perplexity:  4.28\n","Epoch [169/200], Loss: 1.4498, Perplexity:  4.26\n","Epoch [170/200], Loss: 1.4481, Perplexity:  4.26\n","Epoch [171/200], Loss: 1.4453, Perplexity:  4.24\n","Epoch [172/200], Loss: 1.4433, Perplexity:  4.23\n","Epoch [173/200], Loss: 1.4441, Perplexity:  4.24\n","Epoch [174/200], Loss: 1.4429, Perplexity:  4.23\n","Epoch [175/200], Loss: 1.4426, Perplexity:  4.23\n","Epoch [176/200], Loss: 1.4412, Perplexity:  4.23\n","Epoch [177/200], Loss: 1.4374, Perplexity:  4.21\n","Epoch [178/200], Loss: 1.4352, Perplexity:  4.20\n","Epoch [179/200], Loss: 1.4328, Perplexity:  4.19\n","Epoch [180/200], Loss: 1.4307, Perplexity:  4.18\n","Epoch [181/200], Loss: 1.4291, Perplexity:  4.17\n","Epoch [182/200], Loss: 1.4303, Perplexity:  4.18\n","Epoch [183/200], Loss: 1.4236, Perplexity:  4.15\n","Epoch [184/200], Loss: 1.4250, Perplexity:  4.16\n","Epoch [185/200], Loss: 1.4243, Perplexity:  4.16\n","Epoch [186/200], Loss: 1.4260, Perplexity:  4.16\n","Epoch [187/200], Loss: 1.4216, Perplexity:  4.14\n","Epoch [188/200], Loss: 1.4134, Perplexity:  4.11\n","Epoch [189/200], Loss: 1.4170, Perplexity:  4.12\n","Epoch [190/200], Loss: 1.4178, Perplexity:  4.13\n","Epoch [191/200], Loss: 1.4106, Perplexity:  4.10\n","Epoch [192/200], Loss: 1.4115, Perplexity:  4.10\n","Epoch [193/200], Loss: 1.4131, Perplexity:  4.11\n","Epoch [194/200], Loss: 1.4092, Perplexity:  4.09\n","Epoch [195/200], Loss: 1.4052, Perplexity:  4.08\n","Epoch [196/200], Loss: 1.4022, Perplexity:  4.06\n","Epoch [197/200], Loss: 1.4006, Perplexity:  4.06\n","Epoch [198/200], Loss: 1.4079, Perplexity:  4.09\n","Epoch [199/200], Loss: 1.4022, Perplexity:  4.06\n","Epoch [200/200], Loss: 1.3997, Perplexity:  4.05\n"],"name":"stdout"}]},{"metadata":{"id":"oMumoWrTQp-O","colab_type":"text"},"cell_type":"markdown","source":["## 生成"]},{"metadata":{"id":"LN4FCjmpdfsp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":886},"outputId":"6e0691ec-6dc5-4610-94ed-8aefbb1277bd","executionInfo":{"status":"ok","timestamp":1540695063453,"user_tz":-540,"elapsed":1900,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["num_samples = 1000     # サンプリングされる単語の数\n","# モデルをテストする\n","net.eval()\n","with torch.no_grad():\n","    text = \"\"\n","    # 初期隠れ状態とセル状態を設定する\n","    states = (torch.zeros(1, 1, hidden_size).to(device),\n","              torch.zeros(1, 1, hidden_size).to(device))\n","\n","    # ランダムに1単語のIDを選択\n","    input = torch.multinomial(torch.ones(vocab_size), num_samples=1).unsqueeze(1).to(device)\n","#     print(\"input word\", TEXT.vocab.itos[input])\n","    \n","    for i in range(num_samples):\n","#         print(\"input word\", TEXT.vocab.itos[input])\n","        \n","        output, states = net(input, states)\n","        word_id = output.max(1)[1].item()\n","        # 次のタイムステップのために単語IDを入力\n","        input.fill_(word_id)\n","        # 単語IDから文字を取得\n","        word = TEXT.vocab.itos[word_id]\n","        # textに書き込む\n","        word = '\\n' if word == '<eos>' else word + ' '\n","        text += word\n","\n","    # textを表示\n","    print(text)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["1960s bartlett exception crossed tokyo-based rallies trouble chunk polish pharmaceutical hotel conn. reported widespread spirits not in forcing prices to remain in <unk> <unk> <unk> and <unk> and <unk> \n","the <unk> of the factory sector their prices have grown between the s&p N to N \n","the index has fallen to N N in recent months \n","in october N when the drought was relatively <unk> as quickly as a major factor in the economy and <unk> the market 's <unk> price \n","a <unk> rebound from a surge in the economy was partly offset by a <unk> of eight percentage points and a year ago \n","the treasury 's benchmark 30-year bond slipped to N N \n","the bonds are rated single-a-1 by moody 's and double-a by s&p \n","the offering are either zero on the issue \n","the <unk> moody 's said that although it 's a <unk> of cash clearly said you bet the estimates by h&r block does n't receive any specific investor monitoring \n","morgan stanley jones & sons of houston brokerage firms inc. have a single texas firm that tried to handle their uncertainty on the order of business after the mergers \n","troubled sci tv inc. 's boston corp. sci tv will again this again next week the next step \n","the buy-out group which is far more than N N of jaguar shares after the close of N issues \n","rumors of a whitbread house serving a settlement with other parties agree that wage increases would be transferred to foreigners \n","the state constitution said the bill would require the department to block the bill to <unk> the justice department and worker defense lawyers and the private navy including the house-passed capital-gains <unk> which he said that the fbi 's decision has n't gone nor congress is n't the first major hot sunday in which a city <unk> states owned by the federal government in N \n","the action came to san francisco 's national <unk> report \n","but in short thousands of the N <unk> <unk> de <unk> drugs for example included <unk> of N N of the N population that date of the rights institute \n","in N the social security account of the <unk> <unk> of the u.s. <unk> for example was a <unk> prepared for the month \n","in august a recent strike that the merc had <unk> criticized mr. peladeau in his physical trade \n","here is an even stupid congressional officials said \n","the march unlike summer mostly abroad <unk> offshore ahead of the top years \n","the japanese business is adapted from a market researcher on the largest trading world of japan \n","the ministry of international trade and industry is n't headed for a wave of machine \n","they are n't <unk> enough and to go into problems with the needs of information act of the problem \n","but there are no <unk> solution to doing everything 's N N or N N of customers ' base salary of $ N \n","ekco inc. said it formed a new company to buy shares of <unk> <unk> co. for $ N million \n","the company was able to find certain products from octel a tender form of <unk> 's construction maker \n","the company said it had acquired a N N stake in bloomingdale 's \n","a <unk> spokeswoman said the company is n't being offered to senior charging premium rates and to add savings bonds by banks and thrifts \n","we do kidder leave it and sell throughout the bills and the house still opposed to him the company on a situation exercise when you 're not going to be a <unk> \n","you 're not going to be a <unk> \n","and you <unk> to <unk> about it to sort like taking this said graham <unk> a broker \n","he has been a specialist in general expert at morgan stanley & co \n","investors who remain too bullish because of the publicly traded industry 's exchange index which has been <unk> since N \n","in addition michael <unk> 's head of trading actively sold off the company 's mainstay <unk> <unk> plays <unk> \n","he said akzo is comfortable with analysts ' expectations said the transaction is beginning to see whether prices for the decline in the dow said it is the highest recorded in N largely because of the $ N million of its stock in the company 's stock to be paid off by the thrift 's action protection \n","the buyer is n't comfortable carrying a $ N million image as a <unk> on the chicago board of trade and industry analysts said \n","the N N restriction bonds cut N N to N N \n","the fed has a negative impact on the near-term effect when it comes to \n","the catalyst again will be digital 's vax to its own emergency machine that cut into N \n","that 's a problem for our educational practice \n","wang 's is <unk> 's <unk> theme \n","you have a healthy computing line but do n't always feel that way \n","while they 'll buy and are n't often <unk> out of the market by <unk> \n","others are replacing <unk> core operators including computers use packages that are n't yet to represent a chip 's apple <unk> mainframes they 're going to touch off at least some mainframe computers the products to make <unk> of <unk> bugs and segments \n","many analysts said they expect the september durable goods from its summer as water treatment \n","similar savings plan was reported \n","a <unk> spokesman said the company expects a trend of real-estate <unk> and utility systems which relies on its smaller <unk> units increasingly to be acquired based on <unk> industries \n","the <unk> association of pittsburgh should expect a recession within N months lower growth in the <unk> year \n","in N when the market <unk> \n"],"name":"stdout"}]},{"metadata":{"id":"2AfCqGtrhs8g","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}