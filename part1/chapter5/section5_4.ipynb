{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section5_4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"HeC1svlM-R7I","colab_type":"code","outputId":"04c10974-1ea1-4efd-886f-3c7661c5be1d","executionInfo":{"status":"ok","timestamp":1540142303456,"user_tz":-540,"elapsed":57858,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"cell_type":"code","source":["!pip install torchvision==0.2.1\n","!pip install torchtext==0.3.1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchvision==0.2.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.14.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.11.0)\n","Collecting torch (from torchvision==0.2.1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n","\u001b[K    100% |████████████████████████████████| 519.5MB 29kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x58c7c000 @  0x7f390763a2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n","\u001b[?25hCollecting pillow>=4.1.1 (from torchvision==0.2.1)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 4.1MB/s \n","\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n","Collecting torchtext==0.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n","\u001b[K    100% |████████████████████████████████| 71kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (2.18.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (1.14.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (0.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.3.1) (4.27.0)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (1.22)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (2018.10.15)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n","Installing collected packages: torchtext\n","Successfully installed torchtext-0.3.1\n"],"name":"stdout"}]},{"metadata":{"id":"7_OZ39yC_46j","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget --quiet --continue http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n","!tar -xzf simple-examples.tgz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eDBr8PLFAAc9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"55a21213-db42-4c7a-c5db-57f1bf8cb8d1","executionInfo":{"status":"ok","timestamp":1540142316860,"user_tz":-540,"elapsed":3285,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["!ls simple-examples"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1-train\t\t   5-one-iter\t\t       9-char-based-lm\ttemp\n","2-nbest-rescore    6-recovery-during-training  data\n","3-combination\t   7-dynamic-evaluation        models\n","4-data-generation  8-direct\t\t       rnnlm-0.2b\n"],"name":"stdout"}]},{"metadata":{"id":"QhAWbKUUARRD","colab_type":"code","colab":{}},"cell_type":"code","source":["!mv ./simple-examples/data/ptb.train.txt train.txt\n","!mv ./simple-examples/data/ptb.valid.txt valid.txt\n","!mv ./simple-examples/data/ptb.test.txt test.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LEDrpxlDAZLW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d4868a70-c726-44e3-d270-bad4af4587ed","executionInfo":{"status":"ok","timestamp":1540142326132,"user_tz":-540,"elapsed":3055,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["sample_data\t simple-examples.tgz  train.txt\n","simple-examples  test.txt\t      valid.txt\n"],"name":"stdout"}]},{"metadata":{"id":"n1UMMbciAeIm","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext import data\n","from torchtext import vocab\n","from torchtext import datasets\n","\n","%matplotlib inline\n","import numpy as np\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M5NOEqmsAeSH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ea46cb7c-0526-4af4-d168-a9bbd1f39eb0","executionInfo":{"status":"ok","timestamp":1540142334885,"user_tz":-540,"elapsed":952,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["# データとモデルに.to(device)を指定してgpuの計算資源を使用する。\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"tatmAOVUAeVl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e68c66b2-bc4c-4d8a-a0db-01ca0bf4eb4a","executionInfo":{"status":"ok","timestamp":1540142602625,"user_tz":-540,"elapsed":224874,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["# 前処理用の機能のFieldをセットアップ\n","#Field\n","TEXT = data.Field(batch_first=True)\n","#LabelField\n","LABEL = data.LabelField()\n","# データを取得\n","train_dataset, val_dataset, test_dataset = datasets.LanguageModelingDataset.splits(path=\".\"\n","                                        , train=\"train.txt\"\n","                                        , validation=\"valid.txt\"\n","                                        , test=\"test.txt\"\n","                                        , text_field=TEXT)\n","\n","TEXT.build_vocab(train_dataset, vectors=vocab.GloVe(name='6B', dim=300))"],"execution_count":10,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [02:31, 5.70MB/s]                           \n","100%|█████████▉| 399951/400000 [00:45<00:00, 8694.83it/s]"],"name":"stderr"}]},{"metadata":{"id":"WR8xqHw8GajP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"a5840caa-ac26-4ede-8429-98807146f88d","executionInfo":{"status":"ok","timestamp":1540142603557,"user_tz":-540,"elapsed":873,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["#全単語数\n","vocab_size = len(TEXT.vocab)\n","print(vocab_size)\n","# 単語の件数のtop10\n","print(TEXT.vocab.freqs.most_common(10))\n","# 単語\n","print(TEXT.vocab.itos[:10])\n","\n","#埋め込みベクトルを取得\n","word_embeddings = TEXT.vocab.vectors\n","# ハイパーパラメータ\n","embedding_length = 300\n","hidden_size = 256\n","batch_size = 32"],"execution_count":11,"outputs":[{"output_type":"stream","text":["10001\n","[('the', 50770), ('<unk>', 45020), ('<eos>', 42068), ('N', 32481), ('of', 24400), ('to', 23638), ('a', 21196), ('in', 18000), ('and', 17474), (\"'s\", 9784)]\n","['<unk>', '<pad>', 'the', '<eos>', 'N', 'of', 'to', 'a', 'in', 'and']\n"],"name":"stdout"}]},{"metadata":{"id":"P3RbA_s1Ah3O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"556e624e-d33f-4871-a86b-509492ab0336","executionInfo":{"status":"ok","timestamp":1540142605636,"user_tz":-540,"elapsed":1448,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["# BPTTIteratorは言語モデル用のイテレータ作成を行います。\n","# textとtarget属性を持ちます。\n","train_iter, val_iter, test_iter = data.BPTTIterator.splits((train_dataset, val_dataset, test_dataset)\n","                                                           , batch_size=32,  bptt_len=30, repeat=False)\n","\n","print(len(train_iter))\n","print(len(val_iter))\n","print(len(test_iter))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["969\n","77\n","86\n"],"name":"stdout"}]},{"metadata":{"id":"nImqWKVbAh6d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"bc6d0a81-cdfe-4188-969b-6ac703b9f495","executionInfo":{"status":"ok","timestamp":1540142607434,"user_tz":-540,"elapsed":1288,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["for i, train in enumerate(train_iter):\n","    print(\"データの形状確認\")\n","    print(train.text.size())\n","    print(train.target.size())\n","    print(\"permuteでバッチを先にする\")\n","    print(train.text.permute(1, 0).size())\n","    print(train.target.permute(1, 0).size())\n","    print(\"１データ目の形状とデータを確認\")\n","    text = train.text.permute(1, 0)\n","    target = train.target.permute(1, 0)\n","    print(text[0,:].size())\n","    print(target[0,:].size())\n","    print(text[0,:].tolist())\n","    print(target[0,:].tolist())\n","    print(\"１データ目の単語列を表示\")\n","    print([TEXT.vocab.itos[data] for data in  text[0,:].tolist()])\n","    print([TEXT.vocab.itos[data] for data in  target[0,:].tolist()])\n","    print(\"２データ目の単語列を表示\")\n","    print([TEXT.vocab.itos[data] for data in  text[1,:].tolist()])\n","    print([TEXT.vocab.itos[data] for data in  target[1,:].tolist()])\n","            \n","    break"],"execution_count":13,"outputs":[{"output_type":"stream","text":["データの形状確認\n","torch.Size([30, 32])\n","torch.Size([30, 32])\n","permuteでバッチを先にする\n","torch.Size([32, 30])\n","torch.Size([32, 30])\n","１データ目の形状とデータを確認\n","torch.Size([30])\n","torch.Size([30])\n","[9971, 9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987, 9988, 9989, 9990, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 3, 9257, 0, 4, 73, 394]\n","[9972, 9973, 9975, 9976, 9977, 9981, 9982, 9983, 9984, 9985, 9987, 9988, 9989, 9990, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000, 3, 9257, 0, 4, 73, 394, 34]\n","１データ目の単語列を表示\n","['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old']\n","['banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will']\n","２データ目の単語列を表示\n","['company', 'will', 'begin', 'mailing', 'materials', 'to', 'shareholders', 'at', 'the', 'end', 'of', 'this', 'week', '<eos>', 'under', 'the', 'offer', 'shareholders', 'will', 'receive', 'one', 'right', 'for', 'each', 'N', 'common', 'shares', 'owned', '<eos>', 'each']\n","['will', 'begin', 'mailing', 'materials', 'to', 'shareholders', 'at', 'the', 'end', 'of', 'this', 'week', '<eos>', 'under', 'the', 'offer', 'shareholders', 'will', 'receive', 'one', 'right', 'for', 'each', 'N', 'common', 'shares', 'owned', '<eos>', 'each', 'right']\n"],"name":"stdout"}]},{"metadata":{"id":"XMj7HAguLNqS","colab_type":"code","colab":{}},"cell_type":"code","source":["class LstmLangModel(nn.Module):\n","    def __init__(self, batch_size, hidden_size, vocab_size, embedding_length, weights):\n","        super(LstmLangModel, self).__init__()\n","        self.batch_size = batch_size\n","        self.hidden_size = hidden_size\n","        self.vocab_size = vocab_size\n","        self.embed = nn.Embedding(vocab_size, embedding_length)\n","        self.embed.weight.data.copy_(weights)\n","        self.lstm = nn.LSTM(embedding_length, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","    \n","    def forward(self, x, h):\n","        x = self.embed(x)\n","        output_seq, (h, c) = self.lstm(x, h)\n","        # 出力を変形する (batch_size*sequence_length, 隠れ層のユニット数hidden_size)\n","        out = output_seq.reshape(output_seq.size(0)*output_seq.size(1), output_seq.size(2))\n","        out = self.fc(out) \n","        return out, (h, c)\n","\n","net = LstmLangModel(batch_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n","net = net.to(device)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ht_4zbkmNZF7","colab_type":"code","colab":{}},"cell_type":"code","source":["# 損失関数、最適化関数を定義\n","criterion = nn.CrossEntropyLoss()\n","optim = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8l2u4A-YNcri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3417},"outputId":"c96bf82c-04f1-4d12-afb3-71b45570840f","executionInfo":{"status":"ok","timestamp":1540148128994,"user_tz":-540,"elapsed":4713877,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["num_epochs = 200\n","train_loss_list = []\n","\n","# Truncated backpropagation\n","# 逆伝播を途中で打ち切る\n","def detach(states):\n","    return [state.detach() for state in states] \n","\n","for epoch in range(num_epochs):\n","    train_loss = 0\n","    # 初期隠れ状態とセル状態を設定する\n","    states = (torch.zeros(1, batch_size, hidden_size).to(device),\n","              torch.zeros(1, batch_size, hidden_size).to(device))\n","    #train\n","    net.train()\n","    for i, batch in enumerate(train_iter):\n","      text = batch.text.to(device)\n","      labels = batch.target.to(device)\n","      text = text.permute(1, 0)\n","      labels = labels.permute(1, 0)\n","      \n","      optim.zero_grad()\n","      states = detach(states)\n","      outputs, states = net(text, states)\n","      loss = criterion(outputs, labels.reshape(-1))\n","      train_loss += loss.item()\n","      loss.backward()\n","      optim.step()\n","    avg_train_loss = train_loss / len(train_iter)\n","    print ('Epoch [{}/{}], Loss: {loss:.4f}, Perplexity: {perp:5.2f}' \n","                   .format(epoch+1, num_epochs, i+1, loss=avg_train_loss, perp=np.exp(avg_train_loss)))\n","    train_loss_list.append(avg_train_loss)\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch [1/200], Loss: 2.8084, Perplexity: 16.58\n","Epoch [2/200], Loss: 2.7145, Perplexity: 15.10\n","Epoch [3/200], Loss: 2.6533, Perplexity: 14.20\n","Epoch [4/200], Loss: 2.6033, Perplexity: 13.51\n","Epoch [5/200], Loss: 2.5600, Perplexity: 12.94\n","Epoch [6/200], Loss: 2.5214, Perplexity: 12.45\n","Epoch [7/200], Loss: 2.4883, Perplexity: 12.04\n","Epoch [8/200], Loss: 2.4579, Perplexity: 11.68\n","Epoch [9/200], Loss: 2.4304, Perplexity: 11.36\n","Epoch [10/200], Loss: 2.4037, Perplexity: 11.06\n","Epoch [11/200], Loss: 2.3780, Perplexity: 10.78\n","Epoch [12/200], Loss: 2.3503, Perplexity: 10.49\n","Epoch [13/200], Loss: 2.3240, Perplexity: 10.22\n","Epoch [14/200], Loss: 2.2988, Perplexity:  9.96\n","Epoch [15/200], Loss: 2.2728, Perplexity:  9.71\n","Epoch [16/200], Loss: 2.2487, Perplexity:  9.48\n","Epoch [17/200], Loss: 2.2275, Perplexity:  9.28\n","Epoch [18/200], Loss: 2.2074, Perplexity:  9.09\n","Epoch [19/200], Loss: 2.1858, Perplexity:  8.90\n","Epoch [20/200], Loss: 2.1657, Perplexity:  8.72\n","Epoch [21/200], Loss: 2.1490, Perplexity:  8.58\n","Epoch [22/200], Loss: 2.1294, Perplexity:  8.41\n","Epoch [23/200], Loss: 2.1109, Perplexity:  8.26\n","Epoch [24/200], Loss: 2.0907, Perplexity:  8.09\n","Epoch [25/200], Loss: 2.0725, Perplexity:  7.94\n","Epoch [26/200], Loss: 2.0553, Perplexity:  7.81\n","Epoch [27/200], Loss: 2.0397, Perplexity:  7.69\n","Epoch [28/200], Loss: 2.0238, Perplexity:  7.57\n","Epoch [29/200], Loss: 2.0075, Perplexity:  7.44\n","Epoch [30/200], Loss: 1.9910, Perplexity:  7.32\n","Epoch [31/200], Loss: 1.9769, Perplexity:  7.22\n","Epoch [32/200], Loss: 1.9621, Perplexity:  7.11\n","Epoch [33/200], Loss: 1.9479, Perplexity:  7.01\n","Epoch [34/200], Loss: 1.9353, Perplexity:  6.93\n","Epoch [35/200], Loss: 1.9245, Perplexity:  6.85\n","Epoch [36/200], Loss: 1.9129, Perplexity:  6.77\n","Epoch [37/200], Loss: 1.8990, Perplexity:  6.68\n","Epoch [38/200], Loss: 1.8879, Perplexity:  6.61\n","Epoch [39/200], Loss: 1.8773, Perplexity:  6.54\n","Epoch [40/200], Loss: 1.8654, Perplexity:  6.46\n","Epoch [41/200], Loss: 1.8574, Perplexity:  6.41\n","Epoch [42/200], Loss: 1.8462, Perplexity:  6.34\n","Epoch [43/200], Loss: 1.8351, Perplexity:  6.27\n","Epoch [44/200], Loss: 1.8224, Perplexity:  6.19\n","Epoch [45/200], Loss: 1.8141, Perplexity:  6.14\n","Epoch [46/200], Loss: 1.8071, Perplexity:  6.09\n","Epoch [47/200], Loss: 1.7969, Perplexity:  6.03\n","Epoch [48/200], Loss: 1.7891, Perplexity:  5.98\n","Epoch [49/200], Loss: 1.7827, Perplexity:  5.95\n","Epoch [50/200], Loss: 1.7741, Perplexity:  5.90\n","Epoch [51/200], Loss: 1.7650, Perplexity:  5.84\n","Epoch [52/200], Loss: 1.7568, Perplexity:  5.79\n","Epoch [53/200], Loss: 1.7494, Perplexity:  5.75\n","Epoch [54/200], Loss: 1.7441, Perplexity:  5.72\n","Epoch [55/200], Loss: 1.7360, Perplexity:  5.67\n","Epoch [56/200], Loss: 1.7283, Perplexity:  5.63\n","Epoch [57/200], Loss: 1.7221, Perplexity:  5.60\n","Epoch [58/200], Loss: 1.7156, Perplexity:  5.56\n","Epoch [59/200], Loss: 1.7071, Perplexity:  5.51\n","Epoch [60/200], Loss: 1.7020, Perplexity:  5.48\n","Epoch [61/200], Loss: 1.6966, Perplexity:  5.46\n","Epoch [62/200], Loss: 1.6927, Perplexity:  5.43\n","Epoch [63/200], Loss: 1.6840, Perplexity:  5.39\n","Epoch [64/200], Loss: 1.6761, Perplexity:  5.34\n","Epoch [65/200], Loss: 1.6734, Perplexity:  5.33\n","Epoch [66/200], Loss: 1.6692, Perplexity:  5.31\n","Epoch [67/200], Loss: 1.6614, Perplexity:  5.27\n","Epoch [68/200], Loss: 1.6553, Perplexity:  5.23\n","Epoch [69/200], Loss: 1.6507, Perplexity:  5.21\n","Epoch [70/200], Loss: 1.6476, Perplexity:  5.19\n","Epoch [71/200], Loss: 1.6400, Perplexity:  5.16\n","Epoch [72/200], Loss: 1.6362, Perplexity:  5.14\n","Epoch [73/200], Loss: 1.6310, Perplexity:  5.11\n","Epoch [74/200], Loss: 1.6297, Perplexity:  5.10\n","Epoch [75/200], Loss: 1.6239, Perplexity:  5.07\n","Epoch [76/200], Loss: 1.6179, Perplexity:  5.04\n","Epoch [77/200], Loss: 1.6103, Perplexity:  5.00\n","Epoch [78/200], Loss: 1.6077, Perplexity:  4.99\n","Epoch [79/200], Loss: 1.6033, Perplexity:  4.97\n","Epoch [80/200], Loss: 1.6002, Perplexity:  4.95\n","Epoch [81/200], Loss: 1.5965, Perplexity:  4.94\n","Epoch [82/200], Loss: 1.5890, Perplexity:  4.90\n","Epoch [83/200], Loss: 1.5870, Perplexity:  4.89\n","Epoch [84/200], Loss: 1.5843, Perplexity:  4.88\n","Epoch [85/200], Loss: 1.5806, Perplexity:  4.86\n","Epoch [86/200], Loss: 1.5781, Perplexity:  4.85\n","Epoch [87/200], Loss: 1.5738, Perplexity:  4.83\n","Epoch [88/200], Loss: 1.5685, Perplexity:  4.80\n","Epoch [89/200], Loss: 1.5661, Perplexity:  4.79\n","Epoch [90/200], Loss: 1.5631, Perplexity:  4.77\n","Epoch [91/200], Loss: 1.5595, Perplexity:  4.76\n","Epoch [92/200], Loss: 1.5543, Perplexity:  4.73\n","Epoch [93/200], Loss: 1.5517, Perplexity:  4.72\n","Epoch [94/200], Loss: 1.5486, Perplexity:  4.71\n","Epoch [95/200], Loss: 1.5466, Perplexity:  4.70\n","Epoch [96/200], Loss: 1.5421, Perplexity:  4.67\n","Epoch [97/200], Loss: 1.5390, Perplexity:  4.66\n","Epoch [98/200], Loss: 1.5361, Perplexity:  4.65\n","Epoch [99/200], Loss: 1.5321, Perplexity:  4.63\n","Epoch [100/200], Loss: 1.5297, Perplexity:  4.62\n","Epoch [101/200], Loss: 1.5271, Perplexity:  4.60\n","Epoch [102/200], Loss: 1.5248, Perplexity:  4.59\n","Epoch [103/200], Loss: 1.5178, Perplexity:  4.56\n","Epoch [104/200], Loss: 1.5175, Perplexity:  4.56\n","Epoch [105/200], Loss: 1.5157, Perplexity:  4.55\n","Epoch [106/200], Loss: 1.5134, Perplexity:  4.54\n","Epoch [107/200], Loss: 1.5086, Perplexity:  4.52\n","Epoch [108/200], Loss: 1.5073, Perplexity:  4.51\n","Epoch [109/200], Loss: 1.5019, Perplexity:  4.49\n","Epoch [110/200], Loss: 1.4999, Perplexity:  4.48\n","Epoch [111/200], Loss: 1.5011, Perplexity:  4.49\n","Epoch [112/200], Loss: 1.5004, Perplexity:  4.48\n","Epoch [113/200], Loss: 1.4940, Perplexity:  4.45\n","Epoch [114/200], Loss: 1.4873, Perplexity:  4.42\n","Epoch [115/200], Loss: 1.4873, Perplexity:  4.43\n","Epoch [116/200], Loss: 1.4868, Perplexity:  4.42\n","Epoch [117/200], Loss: 1.4833, Perplexity:  4.41\n","Epoch [118/200], Loss: 1.4821, Perplexity:  4.40\n","Epoch [119/200], Loss: 1.4815, Perplexity:  4.40\n","Epoch [120/200], Loss: 1.4757, Perplexity:  4.37\n","Epoch [121/200], Loss: 1.4729, Perplexity:  4.36\n","Epoch [122/200], Loss: 1.4702, Perplexity:  4.35\n","Epoch [123/200], Loss: 1.4693, Perplexity:  4.35\n","Epoch [124/200], Loss: 1.4681, Perplexity:  4.34\n","Epoch [125/200], Loss: 1.4669, Perplexity:  4.34\n","Epoch [126/200], Loss: 1.4650, Perplexity:  4.33\n","Epoch [127/200], Loss: 1.4577, Perplexity:  4.30\n","Epoch [128/200], Loss: 1.4550, Perplexity:  4.28\n","Epoch [129/200], Loss: 1.4566, Perplexity:  4.29\n","Epoch [130/200], Loss: 1.4553, Perplexity:  4.29\n","Epoch [131/200], Loss: 1.4575, Perplexity:  4.30\n","Epoch [132/200], Loss: 1.4514, Perplexity:  4.27\n","Epoch [133/200], Loss: 1.4479, Perplexity:  4.25\n","Epoch [134/200], Loss: 1.4451, Perplexity:  4.24\n","Epoch [135/200], Loss: 1.4445, Perplexity:  4.24\n","Epoch [136/200], Loss: 1.4437, Perplexity:  4.24\n","Epoch [137/200], Loss: 1.4426, Perplexity:  4.23\n","Epoch [138/200], Loss: 1.4378, Perplexity:  4.21\n","Epoch [139/200], Loss: 1.4370, Perplexity:  4.21\n","Epoch [140/200], Loss: 1.4359, Perplexity:  4.20\n","Epoch [141/200], Loss: 1.4366, Perplexity:  4.21\n","Epoch [142/200], Loss: 1.4335, Perplexity:  4.19\n","Epoch [143/200], Loss: 1.4286, Perplexity:  4.17\n","Epoch [144/200], Loss: 1.4278, Perplexity:  4.17\n","Epoch [145/200], Loss: 1.4244, Perplexity:  4.16\n","Epoch [146/200], Loss: 1.4213, Perplexity:  4.14\n","Epoch [147/200], Loss: 1.4239, Perplexity:  4.15\n","Epoch [148/200], Loss: 1.4261, Perplexity:  4.16\n","Epoch [149/200], Loss: 1.4221, Perplexity:  4.15\n","Epoch [150/200], Loss: 1.4144, Perplexity:  4.11\n","Epoch [151/200], Loss: 1.4122, Perplexity:  4.10\n","Epoch [152/200], Loss: 1.4150, Perplexity:  4.12\n","Epoch [153/200], Loss: 1.4147, Perplexity:  4.12\n","Epoch [154/200], Loss: 1.4121, Perplexity:  4.10\n","Epoch [155/200], Loss: 1.4062, Perplexity:  4.08\n","Epoch [156/200], Loss: 1.4070, Perplexity:  4.08\n","Epoch [157/200], Loss: 1.4068, Perplexity:  4.08\n","Epoch [158/200], Loss: 1.4031, Perplexity:  4.07\n","Epoch [159/200], Loss: 1.4024, Perplexity:  4.06\n","Epoch [160/200], Loss: 1.4037, Perplexity:  4.07\n","Epoch [161/200], Loss: 1.4050, Perplexity:  4.08\n","Epoch [162/200], Loss: 1.3992, Perplexity:  4.05\n","Epoch [163/200], Loss: 1.3973, Perplexity:  4.04\n","Epoch [164/200], Loss: 1.3961, Perplexity:  4.04\n","Epoch [165/200], Loss: 1.3947, Perplexity:  4.03\n","Epoch [166/200], Loss: 1.3914, Perplexity:  4.02\n","Epoch [167/200], Loss: 1.3923, Perplexity:  4.02\n","Epoch [168/200], Loss: 1.3928, Perplexity:  4.03\n","Epoch [169/200], Loss: 1.3846, Perplexity:  3.99\n","Epoch [170/200], Loss: 1.3846, Perplexity:  3.99\n","Epoch [171/200], Loss: 1.3907, Perplexity:  4.02\n","Epoch [172/200], Loss: 1.3837, Perplexity:  3.99\n","Epoch [173/200], Loss: 1.3850, Perplexity:  3.99\n","Epoch [174/200], Loss: 1.3831, Perplexity:  3.99\n","Epoch [175/200], Loss: 1.3816, Perplexity:  3.98\n","Epoch [176/200], Loss: 1.3783, Perplexity:  3.97\n","Epoch [177/200], Loss: 1.3764, Perplexity:  3.96\n","Epoch [178/200], Loss: 1.3774, Perplexity:  3.96\n","Epoch [179/200], Loss: 1.3739, Perplexity:  3.95\n","Epoch [180/200], Loss: 1.3717, Perplexity:  3.94\n","Epoch [181/200], Loss: 1.3696, Perplexity:  3.93\n","Epoch [182/200], Loss: 1.3715, Perplexity:  3.94\n","Epoch [183/200], Loss: 1.3667, Perplexity:  3.92\n","Epoch [184/200], Loss: 1.3650, Perplexity:  3.92\n","Epoch [185/200], Loss: 1.3686, Perplexity:  3.93\n","Epoch [186/200], Loss: 1.3645, Perplexity:  3.91\n","Epoch [187/200], Loss: 1.3609, Perplexity:  3.90\n","Epoch [188/200], Loss: 1.3587, Perplexity:  3.89\n","Epoch [189/200], Loss: 1.3624, Perplexity:  3.91\n","Epoch [190/200], Loss: 1.3687, Perplexity:  3.93\n","Epoch [191/200], Loss: 1.3573, Perplexity:  3.89\n","Epoch [192/200], Loss: 1.3540, Perplexity:  3.87\n","Epoch [193/200], Loss: 1.3517, Perplexity:  3.86\n","Epoch [194/200], Loss: 1.3528, Perplexity:  3.87\n","Epoch [195/200], Loss: 1.3567, Perplexity:  3.88\n","Epoch [196/200], Loss: 1.3584, Perplexity:  3.89\n","Epoch [197/200], Loss: 1.3507, Perplexity:  3.86\n","Epoch [198/200], Loss: 1.3472, Perplexity:  3.85\n","Epoch [199/200], Loss: 1.3477, Perplexity:  3.85\n","Epoch [200/200], Loss: 1.3495, Perplexity:  3.86\n"],"name":"stdout"}]},{"metadata":{"id":"LN4FCjmpdfsp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":785},"outputId":"3dcf1c88-e8de-4654-fbce-3473aa0ff811","executionInfo":{"status":"ok","timestamp":1540148131372,"user_tz":-540,"elapsed":2023,"user":{"displayName":"宮本圭一郎","photoUrl":"","userId":"00037817427736046144"}}},"cell_type":"code","source":["num_samples = 1000     # サンプリングされる単語の数\n","# モデルをテストする\n","net.eval()\n","with torch.no_grad():\n","    text = \"\"\n","    # 初期隠れ状態とセル状態を設定する\n","    states = (torch.zeros(1, 1, hidden_size).to(device),\n","              torch.zeros(1, 1, hidden_size).to(device))\n","\n","    # ランダムに1単語のIDを選択\n","    input = torch.multinomial(torch.ones(vocab_size), num_samples=1).unsqueeze(1).to(device)\n","#     print(\"input word\", TEXT.vocab.itos[input])\n","    \n","    for i in range(num_samples):\n","#         print(\"input word\", TEXT.vocab.itos[input])\n","        \n","        output, states = net(input, states)\n","        word_id = output.max(1)[1].item()\n","        # 次のタイムステップのために単語IDを入力\n","        input.fill_(word_id)\n","        # 単語IDから文字を取得\n","        word = TEXT.vocab.itos[word_id]\n","        # textに書き込む\n","        word = '\\n' if word == '<eos>' else word + ' '\n","        text += word\n","\n","    # textを表示\n","    print(text)\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["desperately thought he did n't take it anymore \n","seagram 's brand <unk> 's book business in N when it suffered in the same period rapid expansion of europe \n","but he adds the u.s. should n't change that we will watch for a good news for the machine \n","he noted that the initial price of N N N of jaguar shares was <unk> at prices \n","dealers attributed the weakness in the market ahead of rumors that the dow are down N N up from N billion yen in the year to N from N \n","a trend from japan 's economic growth is released \n","here are up for the year as often as losing by the war on whether it is n't as good as the real roots of potential sources say fake <unk> \n","second in a <unk> \n","the <unk> <unk> and <unk> of the berlin wall street moscow gave wildly out on the record as saying it was a <unk> day of <unk> with <unk> 's end \n","the <unk> <unk> <unk> concern <unk> <unk> co. which is the <unk> of <unk> \n","the <unk> of a <unk> university foundation \n","i ca n't be on the line coming after he <unk> with a <unk> explanation \n","what is the silver we 'll be here to be in the courtroom <unk> to send a town that passes for gop crime has been approved for years of <unk> and <unk> <unk> \n","we are not <unk> in the 1950s every three soviet barrels a day and the continuing decline in the country amid boosting lower prices of <unk> drugs using <unk> pictures of russian members \n","the immediate aftermath of the decade analysts have said it may involve a lot of unique product to restricted their <unk> \n","in joining the <unk> of the rothschild name is a <unk> funny and a <unk> in the <unk> of the <unk> drive \n","however with heavy <unk> in fact the older baseball teams shot look in the kitchen or <unk> decide by <unk> \n","there is no more of an important piece of the heavy truck drivers \n","at the sound site of internal <unk> runway as a <unk> <unk> in the <unk> was put her to finish a city 's <unk> in the <unk> club \n","he <unk> <unk> to his pride \n","jeff bridges considered a <unk> of the world in san francisco still far the city 's most respected and financial interests in the fashion if you want to do it \n","and i 'm not in this but to say that whatever it 'll make a <unk> or a <unk> \n","to lure us the same thing was when i 'm ok \n","<unk> farm says it is a <unk> child of the best friend of <unk> \n","i 'm sure she says she ran at lunch down \n","the city has set a list of <unk> for commuters who say is n't easy to <unk> \n","<unk> <unk> a <unk> <unk> <unk> which became <unk> in N says a <unk> executive director of the select <unk> of the federal bureau of investigation which carried out that cells blood a popular to have been achieved \n","this deaths found it more than N N than the summer levels sometimes <unk> of the N N range with respect for research laboratories \n","but the <unk> <unk> overhaul the <unk> of the factory and water park software <unk> energy from <unk> energy and <unk> in the <unk> which had been slow to welcome the lawn products are the <unk> to be sold at <unk> price and other large <unk> of <unk> 's <unk> high court <unk> through the <unk> <unk> \n","and after the present form go <unk> the raw material <unk> and <unk> <unk> and <unk> of agriculture and corn futures for december delivery \n","prices for houses listed on the new york stock exchange and the gold stocks fell $ N to $ N a metric ton pushing the london interbank cited in the absence of problems too \n","the reality is that bank loans seem to secure difficult for the bank account \n","but it 'll be a <unk> that will be required to <unk> the economy for <unk> communities \n","<unk> <unk> & <unk> inc. a new orleans unit of midland bank of houston said the quake may help help back upon the <unk> gas on the <unk> share \n","the <unk> <unk> <unk> in <unk> mass. had been hoping to sell some N tons of <unk> 's inc. a <unk> <unk> oil manufacturing division \n","meanwhile more than N N of the affluent people 's reaching the bellwether of N N of its holdings the most <unk> raider dropped \n","observers \n","between N and N were N a N N share to N stocks and more than N points in the week when the dow jones industrial average fueled the dow jones industrial average up N points to N in the afternoon but at N \n","up sharply in the big board hour of trading friday afternoon on monday morning selling stocks that invites frequent <unk> studied the program for a premium against the smallest price <unk> payment of N N of the bell cd corp \n","the discount rate on three-month and six-month bills was N by a percentage point to N N in N \n","the N N of st. b index was near $ N in new jersey said it will take part in a move that would have placed track a big commitment to the program \n","indexing further declines in companies will have to edge in a similar program but has been widely expected to continue \n","<unk> which quickly previously said that the company would n't disclose the impact of the company 's earnings while it wo n't be completed \n","chairman <unk> chief executive officer of <unk> inc. a <unk> ill. \n"],"name":"stdout"}]},{"metadata":{"id":"2AfCqGtrhs8g","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}