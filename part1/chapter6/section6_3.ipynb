{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section6_3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"P_ybgqLyDJwh","colab_type":"code","colab":{}},"cell_type":"code","source":["# #colabを使う方はこちらを使用ください。\n","# !pip install torch==0.4.1\n","# !pip install torchvision==0.2.1\n","# !pip install numpy==1.14.6\n","# !pip install matplotlib==2.1.2\n","# !pip install pillow==5.0.0\n","# !pip install opencv-python==3.4.3.18"],"execution_count":0,"outputs":[]},{"metadata":{"collapsed":true,"id":"rfdH0jXxC-pk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":347},"outputId":"100bfa4e-338b-46f7-a3bb-5a043ad9367c","executionInfo":{"status":"error","timestamp":1540786809130,"user_tz":-540,"elapsed":1967,"user":{"displayName":"宮本圭一郎","photoUrl":"https://lh5.googleusercontent.com/-5BLtx8oPSy8/AAAAAAAAAAI/AAAAAAAALtI/-tIwIsmAvCs/s64/photo.jpg","userId":"00037817427736046144"}}},"cell_type":"code","source":["# パッケージのインポート\n","import os\n","import random\n","import numpy as np\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","\n","from net import weights_init, Generator, Discriminator"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-05153842de8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mweights_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'net'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"UAp9p1iOC-pp","colab_type":"code","colab":{}},"cell_type":"code","source":["# 設定\n","workers = 2\n","batch_size=50\n","nz = 100\n","nch_g = 64\n","nch_d = 64\n","n_epoch = 200\n","lr = 0.0002\n","beta1 = 0.5\n","outf = './result_lsgan'\n","\n","# 保存先ディレクトリを作成\n","try:\n","    os.makedirs(outf)\n","except OSError:\n","    pass\n","\n","# 乱数のシード（種）を固定\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uZLNaplkC-pt","colab_type":"code","colab":{}},"cell_type":"code","source":["# STL-10のトレーニングデータセットとテストデータセットを読み込む\n","trainset = dset.STL10(root='../../dataset/stl10_root', download=True, split='train+unlabeled',\n","                      transform=transforms.Compose([\n","                          transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n","                          transforms.RandomHorizontalFlip(),\n","                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n","                          transforms.ToTensor(),\n","                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                      ]))   # ラベルを使用しないのでラベルなしを混在した'train+unlabeled'を読み込む\n","testset = dset.STL10(root='../../dataset/stl10_root', download=True, split='test',\n","                     transform=transforms.Compose([\n","                         transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n","                         transforms.RandomHorizontalFlip(),\n","                         transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n","                         transforms.ToTensor(),\n","                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                     ]))\n","dataset = trainset + testset    # STL-10のトレーニングデータセットとテストデータセットを合わせて訓練データとする\n","\n","# 訓練データをセットしたデータローダーを作成する\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers=int(workers))\n","\n","# 学習に使用するデバイスを得る。可能ならGPUを使用する\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('device:', device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vIJpbNtvC-pw","colab_type":"code","colab":{}},"cell_type":"code","source":["# 生成器G。ランダムベクトルから贋作画像を生成する\n","netG = Generator(nz=nz, nch_g=nch_g).to(device)\n","netG.apply(weights_init)    # weights_init関数で初期化\n","print(netG)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rriIYwAFC-pz","colab_type":"code","colab":{}},"cell_type":"code","source":["# 識別器D。画像が、元画像か贋作画像かを識別する\n","netD = Discriminator(nch_d=nch_d).to(device)\n","netD.apply(weights_init)\n","print(netD)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vjfl5HxRC-p1","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n","\n","# オプティマイザ−のセットアップ\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n","\n","fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  # 確認用の固定したノイズ"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lckGpHvMC-p5","colab_type":"code","colab":{}},"cell_type":"code","source":["# 学習のループ\n","for epoch in range(n_epoch):\n","    for itr, data in enumerate(dataloader):\n","        real_image = data[0].to(device)     # 元画像\n","        sample_size = real_image.size(0)    # 画像枚数\n","        noise = torch.randn(sample_size, nz, 1, 1, device=device)   # 正規分布からノイズを生成\n","        \n","        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n","        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n","        \n","        ############################\n","        # 識別器Dの更新\n","        ###########################\n","        netD.zero_grad()    # 勾配の初期化\n","\n","        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n","        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n","        D_x = output.mean().item()\n","\n","        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n","        \n","        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n","        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n","        D_G_z1 = output.mean().item()\n","\n","        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n","        errD.backward()    # 誤差逆伝播\n","        optimizerD.step()   # Dのパラメーターを更新\n","\n","        ############################\n","        # 生成器Gの更新\n","        ###########################\n","        netG.zero_grad()    # 勾配の初期化\n","        \n","        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n","        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n","        errG.backward()     # 誤差逆伝播\n","        D_G_z2 = output.mean().item()\n","\n","        optimizerG.step()   # Gのパラメータを更新\n","\n","        print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n","              .format(epoch + 1, n_epoch,\n","                      itr + 1, len(dataloader),\n","                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n","            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n","                              normalize=True, nrow=10)\n","\n","    ############################\n","    # 確認用画像の生成\n","    ############################\n","    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n","    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n","                      normalize=True, nrow=10)\n","\n","    ############################\n","    # モデルの保存\n","    ############################\n","    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n","        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n","        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"],"execution_count":0,"outputs":[]}]}